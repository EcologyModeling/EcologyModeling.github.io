<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Модели логистической регрессии</title>

<script src="site_libs/header-attrs-2.7/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="https://fonts.googleapis.com/css?family=PT+Sans" rel="stylesheet">
<link rel="icon" type="image/png" href="images/favicon.png" />

<script type="text/javascript" src="js/rmarkdown.js"></script>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="css/envmodel.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">



<!--<div id="rStudioHeader" class="alwaysShrunk">
  <div class="innards bandContent">

      <a class="productName" href="index.html">Математическое моделирование в экологии
</a>


    <div id="menu">
      <div id="menuToggler"></div>
      <div id="menuItems">
        <a class="menuItem" href="Part-1-topic-1.html">Занятия</a>
        <a class="menuItem" href="Tests.html">Задания</a>
        <a class="menuItem" href="presentations/Introduction_R.html">Презентации</a>
        <a class="menuItem" href="materials.html">Материалы</a>
        <a class="menuItem gitHub" href="https://github.com/environemental-modelling/environemental-modelling.github.io"></a>
        <a class="menuItem gitHubText" href="https://github.com/environemental-modelling/environemental-modelling.github.io">Source on GitHub</a>
      </div>
    </div>
  </div>
</div>
-->

<div class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <a href="index.html" class="navbar-brand">Математическое моделирование в экологии</a>
          <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        </div>
        <div class="navbar-collapse collapse" id="navbar-main">
          <ul class="nav navbar-nav navbar-right">
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#" id="themes">Занятия<span class="caret"></span></a>
              <ul class="dropdown-menu" aria-labelledby="themes">

                <li><a href="Part-1-topic-1.html">Введение в R</a></li>
                <li><a href="Part-2-topic-2.html">Физические модели</a></li>
                <li><a href="Part-3-topic-1.html">Манипуляции над данными</a></li>
                <li><a href="Part-4-topic-1.html">Линейная регрессия</a></li>
                <li><a href="Part-4-topic-2.html">Логистическая регрессия</a></li>
                <li><a href="Part-5-topic-1.html">Рандомизация и бутстреп</a></li>
                
              </ul>
            </li>
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#" id="themes">Презентации<span class="caret"></span></a>
              <ul class="dropdown-menu" aria-labelledby="themes">
                <li><a href="presentations/Lecture__1_intr_R_rus.html">Введение в R</a></li>
                <li><a href="presentations/Lecture__2_Frames_functions_rus.html">Таблицы и функции</a></li>
                <li><a href="presentations/Lecture_3_graphs.html">Графика</a></li>
              </ul>
            </li>
            <li><a href="Tests.html" target="_blank">Задания</a></li>
            <li><a href="presentations/Introduction_R.html" target="_blank"></a>Pres</li>
            <li><a href="materials.html" target="_blank">Материалы</a></li>
            <li><a class="menuItem gitHub" href="https://github.com/environemental-modelling/environemental-modelling.github.io"></a>
                <a class="menuItem gitHubText" href="https://github.com/environemental-modelling/environemental-modelling.github.io">Исходники в GitHub</a></li>
          </ul>
    </div>
  </div>
</div>


<style type="text/css">
#TOC {
  margin-left: 35px;
  margin-top: 90px;
}
</style>

<script type="text/javascript">
$(".main-container").removeClass("main-container").removeClass("container-fluid").addClass("footerPushDown");
</script>


<div id="pageContent" class="standardPadding">
  <div class="articleBandContent">
<div class="lessonPage">
  <div class="lessonsNav">
    <a id="nav-lesson-1" href="Part-1-topic-1.html">Введение в программирование на языке R</a>
    <a id="nav-lesson-15" href="Part-2-topic-2.html">Физические модели. Формализация и численные решения.</a>
    <a id="nav-lesson-2" href="Part-3-topic-1.html">Манипуляции над данными</a>
    <a id="nav-lesson-3" href="Part-4-topic-1.html">Создание моделей линейной регрессии</a>
    <a id="nav-lesson-4" href="Part-4-topic-2.html">Модели логистической регрессии</a>
    <a id="nav-lesson-5" href="Part-5-topic-1.html">Дополнительные методы</a>

    <!--<a id="nav-lesson-5" href="lesson-5.html">Multiple regression modelling</a>
        <a id="nav-lesson-5" href="lesson-5.html">Всякое новое</a>
    <a id="nav-lesson-6" href="lesson-6.html">Parameters</a>
    <a id="nav-lesson-7" href="lesson-7.html">Tables</a>
    <a id="nav-lesson-8" href="lesson-8.html">Markdown Basics</a>
    <a id="nav-lesson-9" href="lesson-9.html">Output Formats</a>
    <a id="nav-lesson-10" href="lesson-10.html">Notebooks</a>
    <a id="nav-lesson-11" href="lesson-11.html">Slide Presentations</a>
    <a id="nav-lesson-12" href="lesson-12.html">Dashboards</a>
    <a id="nav-lesson-13" href="lesson-13.html">Websites</a>
    <a id="nav-lesson-14" href="lesson-14.html">Interactive Documents</a>
    <a id="nav-lesson-15" href="lesson-15.html">Cheatsheets</a>-->
  </div>
  <div class="lessonContent">
    

<div id="header">



<h1 class="title toc-ignore">Модели логистической регрессии</h1>

</div>


<style type="text/css">
  table tr td {
    border: solid 1px lightgray;
    padding: 10px;
  }
  table {
  margin:2em;
  }
</style>
<div id="классификация-данных" class="section level3">
<h3>Классификация данных</h3>
<table>
<colgroup>
<col width="41%" />
<col width="58%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Современная Терминология</strong></td>
<td><strong>Применяемые алгоритмы</strong></td>
</tr>
<tr class="even">
<td>Классификации</td>
<td>Дерево принятия решений Байессовские методы Логистическая регрессия (с порогами) Методо опорных веторов</td>
</tr>
<tr class="odd">
<td>Регрессия: численные предска -зания численных значений</td>
<td>Линейная регрессия <strong>Логистическая регрессия</strong></td>
</tr>
<tr class="even">
<td>Правила агрегации: поиск объектов, которые часто встречаются вместе</td>
<td>Априорные</td>
</tr>
<tr class="odd">
<td>Класетризация: поиск групп объектов, которые более схожи между собой, чем между объек- тами в других группах</td>
<td>K-средние</td>
</tr>
<tr class="even">
<td>Ближайший сосед:предсказываем свойства данных на основе наиболее сходных с ними данных</td>
<td>Метод присоединения соседей</td>
</tr>
</tbody>
</table>
</div>
<div id="тестовая-и-обучающая-выборка" class="section level3">
<h3>Тестовая и обучающая выборка</h3>
<p>Когда вы строите модель, чтобы делать прогнозы, как наша модель для прогнозирования вероятности медицинского страхования, вам нужны данные для построения модели. Вам также понадобятся данные для проверки того делает ли наша модель верные предсказания на новых данных. Первая выборка называется обучающей, а второй набор называется тестировочным. Обучающий набор данных, это тот который вы “скармливаете” модели, так что алгоритм может установить правильные параметры, чтобы наиболее точно предсказать результат зависимой переменной. Тестовый набор данных, вы используете для “скармливания” результирующей модели, чтобы убедиться, что предсказания модели являются точными.</p>
<p>Многие авторы рекомендуют тестировочное/калибровочное/обучающее разбиение, что тоже хорошо. Мы предлагаем следующее: разбить данные на обучающие/тестировочные в начале, не использовать тестировочные данные до конца моделирования, и если вам нужны калибровочные данные, переразбить их из обучающего подмножества .</p>
</div>
<div id="коррелляции-при-моделировании" class="section level3">
<h3>Коррелляции при моделировании</h3>
<p>Корреляции очень полезно при проверке, являются ли переменные потенциально полезными для модели. Помните, что есть по крайней мере три подхода, которые известны под именем корреляции: Пирсона, Спирмена и Кендалла (см. help(cor)). Пирсона применяют для линейных отношений, Спирмана для ранговых или сильно ненормальных данных. Каждый из этих коэффициентов выполняет все более радикальные преобразования над исходными данными, и имеет хорошо разработанные тесты для оценки точности (см. help(кор.тест)).</p>
<p><strong><em>НЕ ИСПОЛЬЗУЙТЕ КОЭФФИЦИЕНТ КОРЕЛЛЯЦИИ ДЛЯ ОЦЕНКИ КАЧЕСТВА РЕАЛЬНЫХ МОДЕЛЕЙ</em></strong></p>
<p>Очень заманчиво использовать корреляцию для оценки качества модели, но мы настоятельно рекомендуем не полагаться исключительно на него. Проблема заключается в следующем: корреляция игнорирует сдвиги и масштаб данных. По сути корелляция показывает, показывает только возможность наличия связи. Вы можете спокойно использовать его для оценок промежуточных моделей(так как эти предсказания, как правило, не имеют систематического смещения или масштабирования по дизайну), но может маскировать систематические ошибки, которые могут возникнуть, когда модель используется в производстве.</p>
<p><strong><em>ХУДШЕЕ ЧТО МОЖЕТ СЛУЧИТЬСЯ ПРИ МОДЕЛИРОВАНИИ</em></strong></p>
<p>Самый худший возможный результат моделирования не отсутствие хорошей модели в итоге вашей работы. Самый худший возможный результат моделирования это уверенность в том, что у вас хорошая модель, когда на самом деле она таковой не является. Один из самых простых способов, чтобы нарваться на подобную ситуацию является наличие инструментальной или независимой переменной, являющейся хитрым неочевидным преобразованием зависимой переменной. Такие переменные могут легко просочиться в вашу обучающую выборку, особенно если у вас нет полного представления о природе каждой переменной.</p>
<p>При построении модели, в первую очередь проверьте, работает ли модель на данных, которые были использованы для ее обучени. Введенем количественные меры оценки эффективности модели. С точки зрения оценки , мы таким образом группируем модели по типам .</p>
<ol style="list-style-type: decimal">
<li>Классификация</li>
<li>Балловая оценка</li>
<li>Оценка вероятности</li>
<li>Ранжирование</li>
<li>Кластеризация</li>
</ol>
<table>
<colgroup>
<col width="13%" />
<col width="86%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Нулевая модель</td>
<td>Нулевая модель это лучшая модель в наиболее простой из возможных форм, которую вы пытаетесь превзойти. Два самых простых варианта это модель в виде одной константы (дает всегда один ответ во всех случаях) или полностью независимая модель ( не отмечает важных отношений или взаимодействий между зависимой и независимыми переменными). Нуль модели важны для оценки нижнего предела необходимой производительности, т.е. сравниваем нашу модель с лучшей из возможных нуль моделей Например при категориальном моделировании, нуль модель всегда будет возвращать наиболее популярную категорию (что, очевидно, часто не верно); для оценочных моделей, нулевая модель часто является средним всех зависимых значений ( так как среднее обладает наименьшим квадратом отклонений); и т.д. Идея заключается в том, что если вы не превосходите по точности нулевую модель, вы отказываетесь от своего предсказания (моделью). Стоит отметить, что часто сложно превзойти нулевую модель, т.к. не смотря на свою простоту она уже выбрана исходя из того рапределения, которым обладают данные. Мы всегда исходим из того, что нулевая модель с которой мы проводим сравнения нашей модели лучшая из всех возможных нуль моделей.</td>
</tr>
<tr class="even">
<td>Байесовские модели</td>
<td>Байесовские модели (часто называемые насыщенными) лучшие возможные модели для имеющихся в данный момент данных. Эти модели явялются идеальными при условии, что не существует разных значениий зависимой переменной при одном и том же значении независимой. Создание Байесовских моделей не всегда практично, но мы будем рассматривать его, как лучший из возможных результатов моделирования. Если вы понимаете, что ваша модель работает значительно лучше нулевой модели и по качеству предсказания приближается к Байесовской, то оптимизацию данной модели можно прекратить. В ситуации обилия данных и малого количества переменных для моделирования, можно рассчитать оценку Байесовской ошибки. Другой способ Байесовской оценки это попросить других аналогично оценить некоторую часть ваших данных, среднее этих оценок можно считать Байесовской оценкой</td>
</tr>
</tbody>
</table>
</div>
<div id="таблица-сопряженности" class="section level3">
<h3>Таблица сопряженности</h3>
<table>
<colgroup>
<col width="36%" />
<col width="31%" />
<col width="31%" />
</colgroup>
<tbody>
<tr class="odd">
<td></td>
<td>Предсказание = Отрицательное</td>
<td>Предсказание = Положиетльное</td>
</tr>
<tr class="even">
<td>Реальное положение = Гипотеза верна</td>
<td>Истинно отрицательный (TN)</td>
<td>Ложноположительный (FP)</td>
</tr>
<tr class="odd">
<td>Реальное положение = Гипотеза НЕ верна</td>
<td>Ложноотрицательный (FN)</td>
<td>Истинно положительный (TP)</td>
</tr>
</tbody>
</table>
</div>
<div id="таблица-метрик-качества-модели" class="section level3">
<h3>Таблица метрик качества модели</h3>
<table style="width:57%;">
<colgroup>
<col width="26%" />
<col width="30%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Показатель</td>
<td>Формула</td>
</tr>
<tr class="even">
<td>Аккуратность</td>
<td>(TP+TN)/(TP+FP+TN+FN)</td>
</tr>
<tr class="odd">
<td>Точность</td>
<td>TP/(TP+FP)</td>
</tr>
<tr class="even">
<td>Чувствительность</td>
<td>TP/(TP+FN)</td>
</tr>
<tr class="odd">
<td>Специфичность</td>
<td>TN/(TN+FP)</td>
</tr>
</tbody>
</table>
</div>
<div id="разъяснение" class="section level3">
<h3>Разъяснение</h3>
<table>
<colgroup>
<col width="13%" />
<col width="86%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Показатель</td>
<td>Типичная бизнесс задача/проблема</td>
</tr>
<tr class="even">
<td>Accuracy Аккуратность</td>
<td>“Нам необходимо, чтобы большинство наших предсказаний было верно.” Можем ли мы себе позволить ошибиться в 5% случаев ? И является ли для пользователей эквивалентной ситуация, когда спам не отмечен как спам, а часть нормальных писем отмечена</td>
</tr>
<tr class="odd">
<td>Precision Точность</td>
<td>“Большая часть того, что мы отметили как спам точно должно быть спамом”. Показатель гарантирует, что большая часть того, что попало в паку спам, действительно спам, но это далеко не лучший способ оценить какая часть реальных писем была потеряна (отнесена к спаму). Большую часть спама действительно легко распрознать, возможно в реальном бизнесе много важнее будет специфичность</td>
</tr>
<tr class="even">
<td>Recall Отзыв</td>
<td>“Мы хотим, чтобы доля спама, которая доходит до пользователя не превышала бы 10%. Если 10% спама проходят сквозь фильтр, будет ли пользователь видеть в основном обычные письма или спам? Повлияет ли это на выбор нас пользователями?”</td>
</tr>
<tr class="odd">
<td>Sensitivity Чувств-ность</td>
<td>“Мы должны отфильтровать большую часть спама, иначе пользователь нас не выберет. “Если мы уменьшим долю спама до 1% от текущего уровня, повлияет ли это на выбор ?”</td>
</tr>
<tr class="even">
<td>Specificity Специф-ть</td>
<td>“Мы должны пропускать 99.9% реальных писем. Потерпит ли пользователь потерю 0,1% от своих писем?”</td>
</tr>
</tbody>
</table>
</div>
<div id="логистическая-регрессия" class="section level2">
<h2>Логистическая регрессия</h2>
<p>Логистическая регрессия является наиболее важным (и, вероятно, наиболее часто используемым) элементом класса моделей, называемых обобщенными линейными моделями. В отличие от линейной регрессии, логистическая регрессия может непосредственно предсказывать значения, которые ограничены интервалом (0,1), таким как вероятности. Это новый метод предсказания вероятностей или коэффициентов, и, подобно линейной регрессии, коэффициенты модели логистической регрессии можно рассматривать как рекомендации. Это также хороший первый выбор для задач двоичной классификации.</p>
<p>В этом разделе мы будем использовать пример из медицинской классификации (прогнозирующий, потребуется ли новорожденному дополнительное медицинское обслуживание) для проработки всех этапов создания и использования модели логистической регрессии.</p>
<div id="понимая-логистическую-регрессию" class="section level3">
<h3>Понимая логистическую регрессию</h3>
<p>Логистическая регрессия предсказывает вероятность того, что объект принадлежит определенной категории, например, вероятность того, что полет будет задержан. Когда x[i,] представляет собой строку входных данных (например, место и время полета, время года, погода, авиаперевозчик), логистическая регрессия находит фиктивную функцию f(x) такую, что</p>
<p><span class="math display">\[P_{y_{[i]} в классе} \sim f_{(x_{[i,]})} = s(a+b_{[1]} x_{[i,1]} + ... b_{[n]} x_{[i,n]})\]</span></p>
<p>Здесь s (z) - так называемая сигмоидальная функция, определяемая как <span class="math inline">\(s(z) = \frac{1}{(1 + exp(z))}\)</span>. Если <span class="math inline">\(y[i]\)</span> - вероятности того, что <span class="math inline">\(x[i,]\)</span> принадлежат интересующему классу (в нашем примере, вероятность того, что полет с определенными характеристиками будет задержан), тогда задача подгонки состоит в том, чтобы найти <span class="math inline">\(b[1 ]\)</span>, …, <span class="math inline">\(b[n]\)</span>, для которых <span class="math inline">\(f(x[i,])\)</span> является наилучшей оценкой <span class="math inline">\(y[i]\)</span>.R предоставляет простую команду для поиска этих коэффициентов: glm (). Обратите внимание, что нам не нужно указывать y[i], которые являются оценками вероятности для запуска glm (); Метод обучения требует только y[i], которые говорят, находится ли данный учебный пример в целевом классе.</p>
<p>Сигмоидная функция отображает действительные числа в интервал (0,1) или вероятности. Обратной к сигмоидной является logit функция, которая определяется как <span class="math inline">\(log(\frac{p}{(1-p)})\)</span>, где p - вероятность. Отношение p / (1-p) известно как вероятность(odds), поэтому в нашем примере про полеты logit представляет собой список вероятностей (или логарифмических коэффициентов), того что полет будет задерживаться. Другими словами, вы можете думать о логистической регрессии как линейной регрессии, которая находит логарифмические коэффициенты вероятност интересующего вас события.</p>
<p>В частности, логистическая регрессия предполагает, что logit(y) является линейным к значениям x. Как и линейная регрессия, логистическая регрессия найдет наилучшие коэффициенты для прогнозирования y, включая поиск выгодных комбинаций и исключений переменных из модели, когда часть независимых переменных коррелированы.</p>
<p>В качестве примерного задания, представьте, что вы работаете в больнице. Цель состоит в том, чтобы разработать план снабжения неонатального оборудования для оказания неотложной помощи в родильных отделениях. Новорожденных младенцев оценивают через 1 и 5 минут после рождения, используя так называемый тест «Апгар», который предназначен для определения того, нуждается ли ребенок в неотложной или экстренной медицинской помощи. Ребенку, который получил оценку ниже 7 (по шкале от 0 до 10) по шкале Апгара, требуется дополнительное внимание.</p>
<p>Такого рода дети встречаются довольно редко, поэтому больницам не хочется тратиться на дополнительное аварийно-спасательное оборудование для каждой поставки. С другой стороны, детям в группе риска может понадобиться помощь при этом очень быстро нужно, поэтому превентивная подготовка может спасти жизнь. Целью данного исследования является попытка выявление ситуаций с повышенной вероятностью риска загодя, для того чтобы ресурсы были распределены точно и загодя.</p>
<pre class="r"><code>sdata = read.csv(&quot;https://www.dropbox.com/s/lx9celfieswn4vq/NatalRisk.csv?dl=1&quot;)
head(sdata)</code></pre>
<pre><code>##      X PWGT UPREVIS CIG_REC    GESTREC3 DPLURAL ULD_MECO ULD_PRECIP ULD_BREECH
## 1 2136  155      14   FALSE &gt;= 37 weeks  single     TRUE      FALSE      FALSE
## 2 2137  140      13   FALSE &gt;= 37 weeks  single    FALSE      FALSE      FALSE
## 3 2138  151      15   FALSE &gt;= 37 weeks  single    FALSE      FALSE      FALSE
## 4 2139  118       4   FALSE &gt;= 37 weeks  single    FALSE      FALSE      FALSE
## 5 2140  134      11   FALSE &gt;= 37 weeks  single    FALSE      FALSE      FALSE
## 6 2141  117      18   FALSE &gt;= 37 weeks  single     TRUE      FALSE      FALSE
##   URF_DIAB URF_CHYPER URF_PHYPER URF_ECLAM atRisk DBWT ORIGRANDGROUP
## 1    FALSE      FALSE      FALSE     FALSE  FALSE 3714             2
## 2    FALSE      FALSE      FALSE     FALSE  FALSE 3715             4
## 3    FALSE      FALSE      FALSE     FALSE  FALSE 3447             2
## 4    FALSE      FALSE      FALSE     FALSE  FALSE 3175             6
## 5    FALSE      FALSE      FALSE     FALSE  FALSE 4038            10
## 6    FALSE      FALSE      FALSE     FALSE  FALSE 3410             7</code></pre>
<pre class="r"><code>train &lt;- sdata[sdata$ORIGRANDGROUP&lt;=5,]
test &lt;- sdata[sdata$ORIGRANDGROUP&gt;5,]</code></pre>
<p>Командой для построения модели логистической регрессии в R является модель glm(). В нашем случае зависимой переменной Y является логическая (булевая) переменная atRisk; все другие переменные в табл. 7.1 представлены независимыми переменными х. Формула для построения модели для прогнозирования atRisk с помощью этих переменных достаточно длинна для линейной записи; поэтому создадим формулу командами показаными в следующем листинге.</p>
<pre class="r"><code>complications &lt;- c(&quot;ULD_MECO&quot;,&quot;ULD_PRECIP&quot;,&quot;ULD_BREECH&quot;)
riskfactors &lt;- c(&quot;URF_DIAB&quot;, &quot;URF_CHYPER&quot;, &quot;URF_PHYPER&quot;,
  &quot;URF_ECLAM&quot;)
  y &lt;- &quot;atRisk&quot;
  x &lt;- c(&quot;PWGT&quot;,
  &quot;UPREVIS&quot;,
  &quot;CIG_REC&quot;,
  &quot;GESTREC3&quot;,
  &quot;DPLURAL&quot;,
  complications,
  riskfactors)
fmla &lt;- paste(y, paste(x, collapse=&quot;+&quot;), sep=&quot;~&quot;)

model &lt;- glm(fmla, data=train, family=binomial(link=&quot;logit&quot;))</code></pre>
<p>Параметры функции glm(), family определяет предполагаемое распределение зависимой переменной Y. В нашем случае, мы моделируем Y как биномиальное распределение, это как если бы мы моделировали результаты броски монеты, вероятность выпадения решки которых зависит от x. Параметр “ссылка” - link поясняет функции каким образом привести модель к линейному виду — преобразует Y через преобразованием указанным в параметре link, а затем моделируем полученное значение линейной функции от переменных x. Комбинирование параметров link и family дают широчайший спектр обобщенных линейных моделей (например, Пуассона, или пробит). Здесь мы будем обсуждать только логистические модели.</p>
<p>Создание прогнозов с логистической моделью аналогично прогнозированию с использованием линейной модели - используйте функцию predict ().</p>
<pre class="r"><code>train$pred &lt;- predict(model, newdata=train, type=&quot;response&quot;)
test$pred &lt;- predict(model, newdata=test, type=&quot;response&quot;)</code></pre>
<p>Мы снова сохранили прогнозы для обучающих и тестовых наборов в качестве столбца pred в соответствующих таблицах Обратите внимание на дополнительный тип параметра = “response”(«ответ»). Он сообщает функции predict () возвращать предсказанные вероятности y. Если вы не укажете type = “response”, то по умолчанию функция predict () вернет вывод link функции - logit(y).</p>
<p>Одно из преимуществ логистической регрессии заключается в том, что она сохраняет предельные вероятности данных обучения. Это означает, что если вы суммируете предсказанные вероятности для всей тренировочной подвыборки, это количество будет равно количеству положительных результатов (atRisk == T) в обучающем наборе. Это справедливо также для подмножеств данных, определяемых переменными, включенными в модель. Например, в подмножестве данных обучения, train$GESTREC == “&lt;37 weeks” (ребенок был преждевременным), сумма прогнозируемых вероятностей равна числу положительных примеров обучения.</p>
<p>Если наша цель заключается в использовании модели для классификации новых образцов в одну из двух категорий (в данном случае - риск-группу или не подверженную риску), мы хотим, чтобы модель давала высокие оценки при отнесении в группу и низкие значениям в противном случае. Мы можем проверить, так ли это, построив распределение баллов для положительных и отрицательных случаев. Давайте сделаем это на обучающем наборе (мы также должны построить тестовый набор, чтобы убедиться, что предсказание аналогичного качества).</p>
<pre class="r"><code>library(ggplot2)
ggplot(train, aes(x=pred, color=atRisk, linetype=atRisk)) + geom_density()</code></pre>
<p><img src="Part-4-topic-2_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>В идеале мы хотели бы, чтобы распределение баллов было разделено, а оценки отрицательных экземпляров (ЛОЖЬ) должны быть сосредоточены слева, а распределение для положительных экземпляров должно быть сосредоточено справа. В данном случае оба распределения сосредоточены слева, что означает, что как положительные, так и отрицательные случаи оцениваются на низком уровне. Это не удивительно, поскольку положительные случаи (те, в которых ребенок находится в группе риска) редки (около 1,8% от всех родов в наборе данных). Распределение оценок для отрицательных случаев уменьшается раньше, чем распределение для положительных экземпляров. Это означает, что модель выявила субпопуляции в данных, где процент новорожденных с повышенным риском выше среднего.</p>
<p>Чтобы использовать модель в качестве классификатора, вы должны выбрать пороговое значение; Баллы выше порога будут классифицироваться как положительные,а те, что ниже, как отрицательные. Когда вы выбираете пороговое значение, вы пытаетесь сбалансировать точность классификатора (какая доля прогнозируемых положительных результатов являются истинно положительными) и его отзыв (сколько из истинных положительных значений находит классификатор)</p>
<p>Если распределения баллов положительных и отрицательных примеров хорошо разделены, как показано на рисунке, мы можем выбрать соответствующий порог в «долине» между двумя пиками. В данном случае два распределения не очень хорошо разделены, что указывает на то, что модель не может построить классификатор, который одновременно обеспечивает хороший отзыв и хорошую точность.Но мы можем создать классификатор, который идентифицирует подмножество ситуаций с более высоким уровнем рождаемости в группе риска, поэтому предварительное выделение ресурсов для этих ситуаций может быть рекомендовано. Мы будем называть отношение точности классификатора к средней скорости срабатывания коэффициентом обогащения. Чем выше мы устанавливаем порог, тем более точным будет классификатор (мы определим набор ситуаций с гораздо более высоким чем средний уровнем точности определения родов с повышенным риском);одновременно мы также будем чаще пропускать(не классифицировать) ситуации, связанные с риском. При выборе порога мы будем использовать обучающий набор, так как выбор порога является частью построения классификатора.</p>
<p>Затем мы можем использовать тестовый набор для оценки производительности классифицируюшей модели . Чтобы помочь подобрать порог, мы можем использовать график, см ниже, который показывает обвременно обогащение и отзыв как функции от пороговго значения. На рисунке, вы видите, что более высокие пороги приводят к более точной классификации, за счет упущения(неправильной классификации) большого количества случаев; Более низкий порог выявит больше критических ситуаций при родах за счет множества ложных срабатываний. Наилучший компромисс между точностью и отзывом зависит от объема ресурсов, которым располагает больница для распределения и сколько их можно оставить в резерве (или перераспределить) для ситуаций, которые пропустил классификатор. Хорошим выбором может стать порог в 0,02 (что, кстати, и составляет общий показатель рождаемости в группах риска). Получающийся классификатор будет идентифицировать набор потенциальных ситуаций с повышенным риском, который обнаруживают примерно половину всех реальных ситуаций, связанных с риском, с истинным положительным уровнем в 2,5 раза выше, чем в среднем(обнаруживаются такие ситуации).</p>
<pre class="r"><code>library(ROCR)
library(ggplot2)
library(gplots)</code></pre>
<pre><code>## 
## Attaching package: &#39;gplots&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     lowess</code></pre>
<pre class="r"><code>library(grid) # Load grid library (you’ll need this  for the nplot function below).
predObj &lt;- prediction(train$pred, train$atRisk) # Create ROCR prediction object
precObj &lt;- performance(predObj, measure=&quot;prec&quot;) # Create ROCR object to calculate precision as a function of threshold
recObj &lt;- performance(predObj, measure=&quot;rec&quot;)# Create ROCR object to calculate recall as a function of threshold.
precision &lt;- (precObj@y.values)[[1]] # ROCR objects are what R calls S4 objects; the slots (or fields) of an S4 object are stored as lists within the object. You extract the slots from an S4 object using @ notation. 
prec.x &lt;- (precObj@x.values)[[1]] # The x values (thresholds) are the same in both predObj and recObj, so you only need to extract them once.
recall &lt;- (recObj@y.values)[[1]]
rocFrame &lt;- data.frame(threshold=prec.x, precision=precision, recall = recall) # Build data frame with thresholds, precision, and recall
nplot &lt;- function(plist) { #Function to plot multiple plots on one page (stacked).
  n &lt;- length(plist)
  grid.newpage()
  pushViewport(viewport(layout=grid.layout(n,1)))
  vplayout=function(x,y) {viewport(layout.pos.row=x, layout.pos.col=y)}
  for(i in 1:n) {
    print(plist[[i]], vp=vplayout(i,1))
    }
}
pnull &lt;- mean(as.numeric(train$atRisk)) # Calculate rate of at-risk births in the training set.
p1 &lt;- ggplot(rocFrame, aes(x=threshold)) + # Plot enrichment rate as a function of threshold.
geom_line(aes(y=precision/pnull)) +
coord_cartesian(xlim = c(0,0.05), ylim=c(0,10) )


p2 &lt;- ggplot(rocFrame, aes(x=threshold)) + # Plot recall as a function of threshold
geom_line(aes(y=recall)) +
coord_cartesian(xlim = c(0,0.05) )
nplot(list(p1, p2)) #Show both plots simultaneously.</code></pre>
<p><img src="Part-4-topic-2_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Как только мы подобрали соответствующий порог, мы можем оценить результирующий классификатор, посмотрев на таблицу показателей точности. Давайте используем тестовый набор для оценки классификатора с порогом 0,02.</p>
<pre class="r"><code>ctab.test &lt;- table(pred=test$pred&gt;0.02, atRisk=test$atRisk)
ctab.test</code></pre>
<pre><code>##        atRisk
## pred    FALSE TRUE
##   FALSE  9487   93
##   TRUE   2405  116</code></pre>
<pre class="r"><code>precision &lt;- ctab.test[2,2]/sum(ctab.test[2,])
precision</code></pre>
<pre><code>## [1] 0.04601349</code></pre>
<pre class="r"><code>recall &lt;- ctab.test[2,2]/sum(ctab.test[,2])
recall</code></pre>
<pre><code>## [1] 0.5550239</code></pre>
<pre class="r"><code>enrich &lt;- precision/mean(as.numeric(test$atRisk))
enrich</code></pre>
<pre><code>## [1] 2.664159</code></pre>
<p>Получающийся классификатор является низкоточным, но идентифицирует набор потенциальных случаев риска, который содержит 55,5% истинных положительных случаев в тестовом наборе, что в 2,66 раза превышает общее среднее. Этот результат хорошо согласуется с результатами тренировочного набора.</p>
<p>Коэффициенты модели логистической регрессии кодируют отношения между входными переменными и выводом путем, подобным тому, как это делают коэффициенты линейной регрессионной модели. Вы можете получить коэффициенты модели с помощью:</p>
<pre class="r"><code>coefficients(model)</code></pre>
<pre><code>##              (Intercept)                     PWGT                  UPREVIS 
##              -2.86700629               0.00376166              -0.06328943 
##              CIG_RECTRUE      GESTREC3&gt;= 37 weeks DPLURALtriplet or higher 
##               0.31316930              -1.54518311               1.39419294 
##              DPLURALtwin             ULD_MECOTRUE           ULD_PRECIPTRUE 
##               0.31231871               0.81842627               0.19172008 
##           ULD_BREECHTRUE             URF_DIABTRUE           URF_CHYPERTRUE 
##               0.74923672              -0.34646672               0.56002503 
##           URF_PHYPERTRUE            URF_ECLAMTRUE 
##               0.16159872               0.49806435</code></pre>
<p>Отрицательные коэффициенты, которые являются статистически значимыми, соответствуют переменным, которые отрицательно коррелируют с шансами (и, следовательно, с вероятностью) положительного результата (т.е. того, что ребенок находится в группе риска). Положительные коэффициенты, которые являются статистически значимыми, положительно коррелируют с шансами положительного результата. Как и в случае линейной регрессии, каждая категориальная переменная расширяется до набора индикаторных переменных. Если исходная переменная имеет n уровней, будет n-1 индикаторных переменных; оставшийся 1 уровень включен в свободный член.</p>
<p>Например, переменная DPLURAL имеет три уровня, соответствующих родам одного ребенка, двойняшкам и тройняшкам или выше. Модель логистической регрессии имеет два соответствующих коэффициента: DPLURALtwin и DPLURALtriplet или выше. Контрольный уровень - обычные роды. Оба коэффициента DPLURAL являются положительными, что указывает на то, что роды нескольких детей имеют более высокие шансы быть подверженными риску, чем обычные роды, при прочих равных условиях.</p>
</div>
<div id="интерпретируя-коэффициенты" class="section level3">
<h3>ИНТЕРПРЕТИРУЯ КОЭФФИЦИЕНТЫ</h3>
<p>Интерпретация значений коэффициентов является немного более сложным, в случае с логистической регрессией, чем в случае с линейной регрессией. Если коэффициент для переменной x[,k] равен b[k], то коэффициенты положительного результата умножаются на коэффициент exp(b[k]) для каждого изменения x[,k] на единицу.</p>
<p>Коэффициент для GESTREC3 &lt;37 недель (для недоношенного ребенка) составляет 1,545183. Так что для недоношенного ребенка вероятность оказаться в опасности равна exp(1,545183) = 4,68883 раз выше по сравнению с младенцем, рожденным в течение полного срока, при условии, что все остальные входные переменные остаются неизменными. В качестве примера предположим, что для полноценного ребенка с определенными характеристиками существует вероятность 1% риска (вероятность равна p / (1-p) или 0,01 / 0,99 = 0,0101); Тогда шансы(odds) для недоношенного малыша с такими же характеристиками составляют 0,0101 * 4,68883 = 0,047. Это соответствует вероятности риска = шанс/ (1 + шанс), или 0,047 / 1,047 - около 4,5%.</p>
<p>Аналогичным образом, коэффициент для UPREVIS (число пренатальных медицинских визитов) составляет около - 0,06. Это означает, что каждый визит в пренатальный период снижает коэффициент риска для младенца, подверженного риску, с коэффициентом exp(-0,06) или примерно 0,94. Предположим, что мать нашего недоношенного ребенка не сделала предродовых визитов; Ребенок в той же ситуации, чья мать совершила три дородовых визита на осмотр, будет иметь шансы на риск около 0,047x0,94x0,94x0,94 = 0,039. Это соответствует вероятности оказаться под угрозой 3,75%.</p>
<p>Таким образом, общим советом в данном случае может быть особый взгляд на преждевременные роды (и множественные роды), а также поощрять будущих матерей совершать регулярные пренатальные посещения</p>
<p>###Считывание сводки модели и определение коэффициентов</p>
<p>Как мы уже упоминали ранее, выводам о значениях коэффициентов можно доверять только , если значения коэффициентов являются статистически значимыми. Мы также хотим убедиться, что модель действительно что-то объясняет. Диагностика в summary модели поможет нам определить некоторые факты о качестве модели.</p>
<pre class="r"><code>summary(model)</code></pre>
<pre><code>## 
## Call:
## glm(formula = fmla, family = binomial(link = &quot;logit&quot;), data = train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.9732  -0.1818  -0.1511  -0.1358   3.2641  
## 
## Coefficients:
##                           Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)              -2.867006   0.285007 -10.059  &lt; 2e-16 ***
## PWGT                      0.003762   0.001487   2.530 0.011417 *  
## UPREVIS                  -0.063289   0.015252  -4.150 3.33e-05 ***
## CIG_RECTRUE               0.313169   0.187230   1.673 0.094398 .  
## GESTREC3&gt;= 37 weeks      -1.545183   0.140795 -10.975  &lt; 2e-16 ***
## DPLURALtriplet or higher  1.394193   0.498866   2.795 0.005194 ** 
## DPLURALtwin               0.312319   0.241088   1.295 0.195163    
## ULD_MECOTRUE              0.818426   0.235798   3.471 0.000519 ***
## ULD_PRECIPTRUE            0.191720   0.357680   0.536 0.591951    
## ULD_BREECHTRUE            0.749237   0.178129   4.206 2.60e-05 ***
## URF_DIABTRUE             -0.346467   0.287514  -1.205 0.228187    
## URF_CHYPERTRUE            0.560025   0.389678   1.437 0.150676    
## URF_PHYPERTRUE            0.161599   0.250003   0.646 0.518029    
## URF_ECLAMTRUE             0.498064   0.776948   0.641 0.521489    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2698.7  on 14211  degrees of freedom
## Residual deviance: 2463.0  on 14198  degrees of freedom
## AIC: 2491
## 
## Number of Fisher Scoring iterations: 7</code></pre>
<p>В линейной регрессии остатки представляют собой вектор различий между истинными значениями моделируемой величины и прогнозируемыми выходными значениями (ошибки). В логистической регрессии остатки отклонений связаны с логарифмическими вероятностями наблюдения истинного результата с учетом предсказанной вероятности этого результата. Идея логарифмического правдоподобия заключается в том, что положительные экземпляры <span class="math inline">\(y\)</span> должны иметь высокую вероятность возникновения <span class="math inline">\(p\)</span> в модели; Отрицательные экземпляры должны иметь низкую вероятность возникновения (или, иначе говоря, <span class="math inline">\((1-p_{y})\)</span> должны быть большими). Функция логарифмического правдоподобия возвращает «совпадение» между результатом <span class="math inline">\(y\)</span> и предсказанной вероятностью <span class="math inline">\(p_{y}\)</span> и наказывает несоответствия (высокий <span class="math inline">\(p_{y}\)</span> для отрицательных случаев и наоборот).</p>
<pre class="r"><code>pred &lt;- predict(model, newdata=train, type=&quot;response&quot;)
llcomponents &lt;- function(y, py) { y*log(py) + (1-y)*log(1-py)} # Function to return the log likelihoods for each data point. Argument y is the true outcome
                                                               # (as a numeric variable, 0/1); argument py is the predicted probability.
edev &lt;- sign(as.numeric(train$atRisk) - pred) * sqrt(-2*llcomponents(as.numeric(train$atRisk), pred)) # Calculate deviance result

summary(edev)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -0.9732 -0.1818 -0.1511 -0.1244 -0.1358  3.2641</code></pre>
<p>Модель линейной регрессии строят, минимизируя сумму квадратов оклонений; модели логистической регрессии можно построить, минимизируя сумму квадратов отклонений остатков, что эквивалентно максимизации логарифмической правдоподобия данных с учетом модели.</p>
<p>Логистические модели также могут использоваться для явного вычисления коэффициентов: для нескольких групп идентичных точек данных (идентичных, кроме исхода) прогнозируют скорость положительных результатов в каждой группе. Такие данные называются сгруппированными данными. В случае сгруппированных данных остатки отклонений могут использоваться в качестве диагностики для подгонки модели. Вот почему остатки отклонений включены в итоговый отчет. Мы используем негруппированные данные - каждая точка данных в обучающем наборе потенциально уникальна. В случае негруппированных данных диагностика подгонки модели, использующая остатки отклонений, более недействительна.</p>
<p>Таблица сводных коэффициентов для логистической регрессии имеет тот же формат, что и таблица коэффициентов для линейной регрессии Столбцы таблицы представляют * имя коэффициента * его предсказанноее значение * ошибка этой оценки * Оценка отличия(со знаком) коэффициента от 0 (используя стандартную ошибку как единицу расстояния) * вероятность увидеть значение коэффициента, по крайней мере такое же большое, как мы наблюдали, при нулевой гипотезе, что значение коэффициента действительно 0</p>
<p>Это последнее значение, называемое p-значением или значимостью, указывает нам, следует ли доверять оценочному значению коэффициента. Стандартное эмпирическое правило состоит в том, что коэффициенты с p-значениями менее 0,05 являются надежными, хотя некоторые исследователи предпочитают более строгие пороговые значения. По данным о рождении мы можем видеть из сводки коэффициентов, что преждевременные роды и рождение тройни являются сильными предикторами новорожденных, нуждающихся в дополнительной медицинской помощи: величины коэффициентов не являются ни пренебрежимо малыми, а значения р указывают на значимость.</p>
<p>Другими переменными, которые влияют на результат, являются вес матери (высокий вес указывают на более высокий риск, что несколько неожиданно); Число медицинских осмотров в пренатальном периоде (чем больше посещений, тем ниже риск); Окрашивание мекония в амниотической жидкости; И положение головы ребенка при рождении. Так же может быть положительная корреляция между курением матери и рождением в группе риска, но данные не указывают на это окончательно. Ни у одной из других переменных нет четкой связи с рождением в группе риска</p>
<p>Девиантность(девиация) тут тоже является показателем того, насколько хорошо модель соответствует данным. Она равна 2-м отрицательным логарифмическим вероятностям для набора данных, учитывая модель. Если вы думаете о девиантности как об аналоге дисперсии, то нулевая девиантность аналогична дисперсии данных с приблизительно средним уровнеи положительных примеров. Девиантность отклонений аналогично приблизительной дисперсии данных модели. Мы можем рассчитать девиантнность как для тренировочных, так и для тестовых наборов.</p>
<pre class="r"><code>loglikelihood &lt;- function(y, py) {
  sum(y * log(py) + (1-y)*log(1 - py))
}
# Function to calculate the log likelihood of a dataset. Variable y is the outcome in numeric form (1 for positive examples, 0 for negative). Variable py is
# the predicted probability that y==1.

pnull &lt;- mean(as.numeric(train$atRisk))
pnull</code></pre>
<pre><code>## [1] 0.01920912</code></pre>
<pre class="r"><code>null.dev &lt;- -2*loglikelihood(as.numeric(train$atRisk), pnull)
null.dev</code></pre>
<pre><code>## [1] 2698.716</code></pre>
<pre class="r"><code>model$null.deviance</code></pre>
<pre><code>## [1] 2698.716</code></pre>
<pre class="r"><code>pred &lt;- predict(model, newdata=train, type=&quot;response&quot;) #Predict probabilities for training data.
resid.dev &lt;- 2*loglikelihood(as.numeric(train$atRisk), pred) # Calculate deviance of model for training data

resid.dev</code></pre>
<pre><code>## [1] -2462.992</code></pre>
<pre class="r"><code>model$deviance # For training data, model deviance is stored in the slot model$deviance</code></pre>
<pre><code>## [1] 2462.992</code></pre>
<pre class="r"><code>testy &lt;- as.numeric(test$atRisk) # Calculate null deviance  and residual deviance for test data.
testpred &lt;- predict(model, newdata=test,
type=&quot;response&quot;)
pnull.test &lt;- mean(testy)
null.dev.test &lt;- -2*loglikelihood(testy, pnull.test)
resid.dev.test &lt;- -2*loglikelihood(testy, testpred)

pnull.test</code></pre>
<pre><code>## [1] 0.0172713</code></pre>
<pre class="r"><code>null.dev.test</code></pre>
<pre><code>## [1] 2110.91</code></pre>
<pre class="r"><code>resid.dev.test</code></pre>
<pre><code>## [1] 1947.094</code></pre>
<p>Первое, что мы можем сделать с нулевыми и остаточными отклонениями, - это проверить, являются ли предсказания вероятности модели лучше, чем просто угадывать среднюю скорость срабатываний статистически. Другими словами, является ли уменьшение отклонения от модели значимым или просто то, что наблюдалось случайно? Это похоже на вычисление статистики F-теста, которая сообщается для линейной регрессии. В случае логистической регрессии тест, который вы запустите, - это тест хи-квадрат. Чтобы сделать это, вам нужно знать степени свободы для нулевой модели и фактической модели (о которых сообщается в резюме). Степени свободы нулевой модели - это количество точек данных минус 1: df.null = dim (train) [[1]] - 1. Степени свободы модели, которую вы подгоните, - это количество точек данных минус Число коэффициентов в модели: df.model = dim (train) [[1]] - length(model$coefficients).</p>
<p>Если количество точек данных в обучающем наборе велико, а df.null - df.model мало, то вероятность разницы в отклонениях null.dev - resid.dev, будучи такой большой, как мы наблюдали, приблизительно распределяется как хи-квадрат со степенями свободы df.null - df.model.</p>
<pre class="r"><code>df.null &lt;- dim(train)[[1]] - 1 # Null model has (number of data points - 1) degrees of freedom.
df.model &lt;- dim(train)[[1]] - length(model$coefficients) # Fitted model has (number of data points - number of coefficients) degrees of freedom.

df.null</code></pre>
<pre><code>## [1] 14211</code></pre>
<pre class="r"><code>df.model</code></pre>
<pre><code>## [1] 14198</code></pre>
<pre class="r"><code>delDev &lt;- null.dev - resid.dev
deldf &lt;- df.null - df.model # Compute difference in deviances and difference in degrees of freedom.
p &lt;- pchisq(delDev, deldf, lower.tail=F) # Estimate probability of seeing the observed difference in deviances under null model (the p-value)
                                         # using chi-squared distribution.

delDev</code></pre>
<pre><code>## [1] 5161.708</code></pre>
<pre class="r"><code>deldf</code></pre>
<pre><code>## [1] 13</code></pre>
<pre class="r"><code>p</code></pre>
<pre><code>## [1] 0</code></pre>
<p>Полезным критерием пригодности, основанным на отклонениях, является псевдо-R-квадрат: 1 - (dev.model / dev.null). Псевдо R-квадрат является аналогом R-квадрата для линейной регрессии. Это показатель того, насколько отклонение «объясняется» моделью. В идеальном случае вы хотите, чтобы псевдо-R-квадрат был близок к 1. Рассчитаем псевдо-R-квадрат как для тестовых, так и для обучающих данных.</p>
<pre class="r"><code>pr2 &lt;- 1-(resid.dev/null.dev)
pr2.test &lt;- 1-(resid.dev.test/null.dev.test)
print(pr2.test)</code></pre>
<pre><code>## [1] 0.07760427</code></pre>
<p>Модель объясняет только 7,7-8,7% отклонения; Это не очень хорошая прогностическая модель (вам следовало бы заподозрить это уже на пред рисунке). Это говорит нам о том, что мы еще не определили все факторы, которые фактически предсказывают рождение детей с повышенным риском. Метод оценки Фишера представляет собой метод итеративной оптимизации, аналогичный методу Ньютона, который использует glm() для нахождения наилучших коэффициентов для модели логистической регрессии. Вы должны ожидать, что он сходится примерно через шесть-восемь итераций. Если итераций больше, чем это, тогда алгоритм может не совпадать, и модель может оказаться недействительной.</p>
</div>
<div id="разделение-и-квази-разделение" class="section level3">
<h3>Разделение и квази-разделение</h3>
<p>Вероятной причиной несведение является разделение или квази-разделение: одна из переменных модели или некоторая комбинация переменных модели предсказывает исход отлично, по крайней мере,на подмножестве обучающих данных. Вы могли бы подумать, что это хорошо, но по иронии судьбы логистическая регрессия терпит неудачу, когда переменные слишком хороши в предсказании. В идеале glm() выдаст предупреждение, когда обнаружит разделение или квази-разделение:</p>
<p>К сожалению, есть ситуации, когда кажется, что никаких предупреждений не выдается, но есть и другие предупреждающие знаки:</p>
<ul>
<li>Необычно большое количество итераций Фишера</li>
<li>Очень большие коэффициенты, как правило, с чрезвычайно большими стандартными ошибками</li>
<li>Остаточные отклонения, превышающие нулевые отклонения</li>
</ul>
<p>Если вы видите какой-либо из этих признаков, модель подозрительна. Чтобы попытаться решить проблему, удалите все переменные с необычно большими коэффициентами; Они, вероятно, вызывают разделение.</p>
</div>
<div id="что-вы-должны-помнить-о-логистической-регрессии" class="section level3">
<h3>Что вы должны помнить о логистической регрессии:</h3>
<ul>
<li>Логистическая регрессия - это метод статистического моделирования для двоичной классификации.</li>
<li>Сначала попробуйте логистическую регрессию, а затем более сложные методы, если логистическая регрессия не работает достаточно хорошо.</li>
<li>Логистическая регрессия будет иметь проблемы с проектами с очень большим числом переменных или категориальными переменными с очень большим количеством уровней.</li>
<li>Логистическая регрессия хорошо откалибрована: она воспроизводит предельные вероятности данных.</li>
<li>Логистическая регрессия может хорошо прогнозировать даже при наличии коррелированных переменных, но коррелированные переменные понижают качество предсказания.</li>
<li>Чрезмерно большие значения коэффициентов, слишком большие стандартные ошибки в оценках коэффициента и неправильный знак коэффициента могут быть показателями коррелированных входных данных.</li>
<li>Слишком много итераций Фишера или слишком большие коэффициенты с очень большими стандартными ошибками могут быть признаками того, что вход или комбинация входов отлично коррелирует с вашей зависимой переменной. Вам может потребоваться сегментировать данные для решения этой проблемы.</li>
<li>gl () обеспечивает хороший набор диагностик, но повторная проверка вашей модели на тестовых данных по-прежнему является наиболее эффективным способом проверки качества.</li>
<li>Pseudo R-squared - полезная эвристика добротности</li>
</ul>
</div>
</div>

</div> <!-- lessonContent -->
</div> <!-- lessonPage -->


<script type="text/javascript">
  var lesson = window.location.href.match(/lesson-[0-9]+/g);
  if (lesson !== null) {
    lesson = 'nav-' + lesson[0];
    $('#'+lesson).addClass('current');
  }

  $('#show-answer').on("click", function() {
    $('#show-answer').addClass('showing');
    $('#model-answer').addClass('showing');
  })
</script>
  </div> <!-- articleBandContent -->
</div> <!-- pageContent -->

<!-- <div id="rStudioFooter" class="band full">
<div class="bandContent">
  <div id="copyright">Создано с помощью R в Лаборатории Агроэкологического Мониторинга и Прогнозирования экосистем - <a href="http://lamp-lab.ru">ЛАМП</a></div>
  <div id="logos">
<a href="https://twitter.com/rstudio" class="footerLogo twitter"></a>
  <a href="https://github.com/rstudio" class="footerLogo gitHub"></a>
   <a href="https://www.linkedin.com/company/rstudio-inc" class="footerLogo linkedIn"></a>
  <a href="https://www.facebook.com/pages/RStudio-Inc/267733656584415" Class="footerLogo facebook"></a>
  </div>
</div>
</div> -->

<div class="navbar navbar-default navbar-fixed-bottom">
    <div class="container">
      <p class="navbar-text pull-left">© 2019 - Создано с помощью R в Лаборатории Агроэкологического Мониторинга и Прогнозирования экосистем -
      <a href="http://lamp-lab.ru">ЛАМП</a>
      </p>
    </div>
</div>


 



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
