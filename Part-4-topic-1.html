<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Создание моделей линейной регрессии</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="https://fonts.googleapis.com/css?family=PT+Sans" rel="stylesheet">
<link rel="icon" type="image/png" href="images/favicon.png" />

<script type="text/javascript" src="js/rmarkdown.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="css/envmodel.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->




<!--<div id="rStudioHeader" class="alwaysShrunk">
  <div class="innards bandContent">

      <a class="productName" href="index.html">Математическое моделирование в экологии
</a>


    <div id="menu">
      <div id="menuToggler"></div>
      <div id="menuItems">
        <a class="menuItem" href="Part-1-topic-1.html">Занятия</a>
        <a class="menuItem" href="Tests.html">Задания</a>
        <a class="menuItem" href="presentations/Introduction_R.html">Презентации</a>
        <a class="menuItem" href="materials.html">Материалы</a>
        <a class="menuItem gitHub" href="https://github.com/environemental-modelling/environemental-modelling.github.io"></a>
        <a class="menuItem gitHubText" href="https://github.com/environemental-modelling/environemental-modelling.github.io">Source on GitHub</a>
      </div>
    </div>
  </div>
</div>
-->

<div class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <a href="index.html" class="navbar-brand">Математическое моделирование в экологии</a>
          <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        </div>
        <div class="navbar-collapse collapse" id="navbar-main">
          <ul class="nav navbar-nav navbar-right">
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#" id="themes">Занятия<span class="caret"></span></a>
              <ul class="dropdown-menu" aria-labelledby="themes">

                <li><a href="Part-1-topic-1.html">Введение в R</a></li>
                <li><a href="Part-2-topic-2.html">Физические модели</a></li>
                <li><a href="Part-3-topic-1.html">Манипуляции над данными</a></li>
                <li><a href="Part-4-topic-1.html">Линейная регрессия</a></li>
                <li><a href="Part-4-topic-2.html">Логистическая регрессия</a></li>
                <li><a href="Part-5-topic-1.html">Рандомизация и бутстреп</a></li>
                
              </ul>
            </li>
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#" id="themes">Презентации<span class="caret"></span></a>
              <ul class="dropdown-menu" aria-labelledby="themes">
                <li><a href="presentations/Lecture__1_intr_R_rus.html">Введение в R</a></li>
                <li><a href="presentations/Lecture__2_Frames_functions_rus.html">Таблицы и функции</a></li>
                <li><a href="presentations/Lecture_3_graphs.html">Графика</a></li>
              </ul>
            </li>
            <li><a href="Tests.html" target="_blank">Задания</a></li>
            <li><a href="presentations/Introduction_R.html" target="_blank"></a>Pres</li>
            <li><a href="materials.html" target="_blank">Материалы</a></li>
            <li><a class="menuItem gitHub" href="https://github.com/environemental-modelling/environemental-modelling.github.io"></a>
                <a class="menuItem gitHubText" href="https://github.com/environemental-modelling/environemental-modelling.github.io">Исходники в GitHub</a></li>
          </ul>
    </div>
  </div>
</div>


<style type="text/css">
#TOC {
  margin-left: 35px;
  margin-top: 90px;
}
</style>

<script type="text/javascript">
$(".main-container").removeClass("main-container").removeClass("container-fluid").addClass("footerPushDown");
</script>


<div id="pageContent" class="standardPadding">
  <div class="articleBandContent">
<div class="lessonPage">
  <div class="lessonsNav">
    <a id="nav-lesson-1" href="Part-1-topic-1.html">Введение в программирование на языке R</a>
    <a id="nav-lesson-15" href="Part-2-topic-2.html">Физические модели. Формализация и численные решения.</a>
    <a id="nav-lesson-2" href="Part-3-topic-1.html">Манипуляции над данными</a>
    <a id="nav-lesson-3" href="Part-4-topic-1.html">Создание моделей линейной регрессии</a>
    <a id="nav-lesson-4" href="Part-4-topic-2.html">Модели логистической регрессии</a>
    <a id="nav-lesson-5" href="Part-5-topic-1.html">Дополнительные методы</a>

    <!--<a id="nav-lesson-5" href="lesson-5.html">Multiple regression modelling</a>
        <a id="nav-lesson-5" href="lesson-5.html">Всякое новое</a>
    <a id="nav-lesson-6" href="lesson-6.html">Parameters</a>
    <a id="nav-lesson-7" href="lesson-7.html">Tables</a>
    <a id="nav-lesson-8" href="lesson-8.html">Markdown Basics</a>
    <a id="nav-lesson-9" href="lesson-9.html">Output Formats</a>
    <a id="nav-lesson-10" href="lesson-10.html">Notebooks</a>
    <a id="nav-lesson-11" href="lesson-11.html">Slide Presentations</a>
    <a id="nav-lesson-12" href="lesson-12.html">Dashboards</a>
    <a id="nav-lesson-13" href="lesson-13.html">Websites</a>
    <a id="nav-lesson-14" href="lesson-14.html">Interactive Documents</a>
    <a id="nav-lesson-15" href="lesson-15.html">Cheatsheets</a>-->
  </div>
  <div class="lessonContent">

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Создание моделей линейной регрессии</h1>

</div>


<div id="-4----" class="section level1">
<h1>Семинар 4 - Построение моделей</h1>
<div class="section level2">
<h2>Корелляция</h2>
<p>Давайте создадим два вектора, ковариацию между которыми мы и попытаемся посчитать</p>
<pre class="r"><code>A=1:3
B=c(3,6,7)</code></pre>
<p>Общая идея ковариации состоит в определении степени взаимноизменения двух групп данных, т.е. на сколько часто изменение одной величины буде совпадать со сходным изменением другой величины. В качестве показателя изменения величины мы будем использовать отклонение от среднего. Посчитаем отклонение от среднего для каждого из наших векторов.</p>
<pre class="r"><code>diff_A &lt;- A - mean(A)
diff_B &lt;- B - mean(B)</code></pre>
<p>Для определения взаимности изменения величин мы перемножим их отклонения от среднего и просумируем результаты. Очевидно, что ковариация будет тем больше, чем чаще у нас совпадали знаки отклонений от среднего, а значит и их “направление”. Так же очевидно, что для того чтобы ковариации выборок разных размеров были сравнимы, мы должны разделить полученную сумму на объем выборки:</p>
<pre class="r"><code>cov &lt;- sum(diff_A*diff_B)/ (length(A)-1)</code></pre>
<p>Отдельно для вычисления стандартного отклонения расчитаем квадраты отклонений от среднего для каждого вектора</p>
<pre class="r"><code>sq_diff_A &lt;- diff_A^2
sq_diff_B &lt;- diff_B^2</code></pre>
<p>Просуммировав квадраты отклонений, разделив их на объем выборки минус 1 и взяв из полученного квадратный корень, мы получим стандартное отклонение.</p>
<pre class="r"><code>sd_A &lt;- sqrt(sum(sq_diff_A)/(length(A)-1))
sd_B &lt;- sqrt(sum(sq_diff_B)/(length(B)-1))</code></pre>
<p>Тогда коэффициентом корреляции двух величин будет называться отношение величины их ковариации к произведению стандартных отклонений каждой из этих величин.</p>
<pre class="r"><code>correlation &lt;- cov/(sd_A*sd_B)
correlation</code></pre>
<pre><code>## [1] 0.9607689</code></pre>
<p>В правильности наших вычислений можно убедиться воспользовавшись функцией cor() языка R</p>
<pre class="r"><code>cor(A,B)</code></pre>
<pre><code>## [1] 0.9607689</code></pre>
<p>Стандартная команда по открытию файлов позволяет точно так же открывать и URL Откроем данные по физической стойкости в переменную PE</p>
<pre class="r"><code>PE &lt;- read.table(&quot;http://assets.datacamp.com/course/Conway/Lab_Data/Stats1.13.Lab.04.txt&quot;, header=TRUE)</code></pre>
<p>Воспользуемся функцией describe из пакета psych, которая дает нам более подробную описательную статистику для всех колонок таблицы, чем стандартные средства.</p>
<pre class="r"><code>library(&quot;psych&quot;)</code></pre>
<pre><code>## Warning: package &#39;psych&#39; was built under R version 3.5.2</code></pre>
<pre class="r"><code>describe(PE)</code></pre>
<pre><code>##             vars   n   mean    sd median trimmed   mad min max range skew
## pid            1 200 101.81 58.85  101.5  101.71 74.87   1 204   203 0.01
## age            2 200  49.41 10.48   48.0   49.46 10.38  20  82    62 0.06
## activeyears    3 200  10.68  4.69   11.0   10.57  4.45   0  26    26 0.30
## endurance      4 200  26.50 10.84   27.0   26.22 10.38   3  55    52 0.22
##             kurtosis   se
## pid            -1.21 4.16
## age            -0.14 0.74
## activeyears     0.46 0.33
## endurance      -0.44 0.77</code></pre>
<p>Построим графики взаимной зависимости переменных возраст(age), количество лет в спорте (activeyears) и физическая стокйость(endurance).</p>
<pre class="r"><code>plot(PE$age~PE$activeyears)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="r"><code>plot(PE$endurance~PE$activeyears)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>plot(PE$endurance~PE$age)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Проведем базовые тесты корреляции для всех переменных</p>
<pre class="r"><code>round(cor(PE[,-1]), 2)  </code></pre>
<pre><code>##               age activeyears endurance
## age          1.00        0.33     -0.08
## activeyears  0.33        1.00      0.33
## endurance   -0.08        0.33      1.00</code></pre>
<p>Сделаем дополнительные тесты. Если нулевая гипотеза об отсутствии корелляции может быть отвергнута с уровнем значимости в 5%, то связь между переменными значимо отличается от нуля с 95% доверительным интервалом.</p>
<pre class="r"><code>cor.test(PE$age, PE$activeyears)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  PE$age and PE$activeyears
## t = 4.9022, df = 198, p-value = 1.969e-06
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.1993491 0.4473145
## sample estimates:
##       cor 
## 0.3289909</code></pre>
<pre class="r"><code>cor.test(PE$age, PE$endurance)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  PE$age and PE$endurance
## t = -1.1981, df = 198, p-value = 0.2323
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.22097811  0.05454491
## sample estimates:
##         cor 
## -0.08483813</code></pre>
<pre class="r"><code>cor.test(PE$endurance, PE$activeyears)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  PE$endurance and PE$activeyears
## t = 4.8613, df = 198, p-value = 2.37e-06
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.1967110 0.4451154
## sample estimates:
##       cor 
## 0.3265402</code></pre>
<p>Вы должны быть осторожны с интерпретацией коэффициентов корреляции при анализе нерепрезентативного образцов. В этом упражнении вы узнаете, как разделить набор данных на подмножества и посмотреть, в какой степени это может изменить коэффициенты корреляции.</p>
<p>Загрузим данные по исследванию последствий сотрясение головного мозга, вызвынных связанными со спортом травмами, которое включает в себя данные опроса как контрольной группоы, так и группы спортсменов, которые пострадали от сотрясения.</p>
<pre class="r"><code>impact=read.csv(&quot;https://dl.dropboxusercontent.com/s/7ubjig9z5hmv858/impact.csv?dl=0&quot;)
describe(impact)</code></pre>
<pre><code>##            vars  n  mean    sd median trimmed   mad   min   max range
## subject       1 40 20.50 11.69  20.50   20.50 14.83  1.00 40.00 39.00
## condition*    2 40  1.50  0.51   1.50    1.50  0.74  1.00  2.00  1.00
## vermem1       3 40 89.75  6.44  91.00   90.44  6.67 75.00 98.00 23.00
## vismem1       4 40 74.88  8.60  75.00   74.97  9.64 59.00 91.00 32.00
## vms1          5 40 34.03  3.90  33.50   34.02  3.62 26.29 41.87 15.58
## rt1           6 40  0.67  0.15   0.65    0.66  0.13  0.42  1.20  0.78
## ic1           7 40  8.28  2.05   8.50    8.38  2.22  2.00 12.00 10.00
## sym1          8 40  0.05  0.22   0.00    0.00  0.00  0.00  1.00  1.00
## vermem2       9 40 82.00 11.02  85.00   82.97  9.64 59.00 97.00 38.00
## vismem2      10 40 71.90  8.42  72.00   72.19 10.38 54.00 86.00 32.00
## vms2         11 40 35.83  8.66  35.15   34.98  6.89 20.15 60.77 40.62
## rt2          12 40  0.67  0.22   0.65    0.65  0.13  0.19  1.30  1.11
## ic2          13 40  6.75  2.98   7.00    6.81  2.97  1.00 12.00 11.00
## sym2         14 40 13.88 15.32   7.00   12.38 10.38  0.00 43.00 43.00
##             skew kurtosis   se
## subject     0.00    -1.29 1.85
## condition*  0.00    -2.05 0.08
## vermem1    -0.70    -0.51 1.02
## vismem1    -0.11    -0.96 1.36
## vms1        0.08    -0.75 0.62
## rt1         1.14     2.21 0.02
## ic1        -0.57     0.36 0.32
## sym1        3.98    14.16 0.03
## vermem2    -0.65    -0.81 1.74
## vismem2    -0.28    -0.87 1.33
## vms2        0.86     0.65 1.37
## rt2         0.93     1.29 0.03
## ic2        -0.16    -1.06 0.47
## sym2        0.44    -1.47 2.42</code></pre>
<p>Посчитаем коэффициенты корелляции между коэффициентвми визуальной и вербальной памяти пациентов.</p>
<pre class="r"><code>entirecorr &lt;- round(cor(impact$vismem2,impact$vermem2),2)</code></pre>
<p>С помощью команды describeBy из пакета psych посомтрим описательные статистики для переменных данной таблицы, сгруппированные по категориям переменной condition - состояние опрошенных. Т.е. посмотрим описательные статистики для контрольной и целевой группы.</p>
<pre class="r"><code>describeBy(impact, impact$condition)</code></pre>
<pre><code>## 
##  Descriptive statistics by group 
## group: concussed
##            vars  n  mean    sd median trimmed   mad   min   max range
## subject       1 20 30.50  5.92  30.50   30.50  7.41 21.00 40.00 19.00
## condition*    2 20  1.00  0.00   1.00    1.00  0.00  1.00  1.00  0.00
## vermem1       3 20 89.65  7.17  92.50   90.56  5.93 75.00 97.00 22.00
## vismem1       4 20 74.75  8.03  74.00   74.25  8.15 63.00 91.00 28.00
## vms1          5 20 33.20  3.62  33.09   33.27  3.32 26.29 39.18 12.89
## rt1           6 20  0.66  0.17   0.63    0.64  0.13  0.42  1.20  0.78
## ic1           7 20  8.55  1.64   9.00    8.62  1.48  5.00 11.00  6.00
## sym1          8 20  0.05  0.22   0.00    0.00  0.00  0.00  1.00  1.00
## vermem2       9 20 74.05  9.86  74.00   73.88 11.86 59.00 91.00 32.00
## vismem2      10 20 69.20  8.38  69.50   69.62 10.38 54.00 80.00 26.00
## vms2         11 20 38.27 10.01  35.15   37.32  7.73 25.70 60.77 35.07
## rt2          12 20  0.78  0.23   0.70    0.74  0.11  0.51  1.30  0.79
## ic2          13 20  5.00  2.53   5.00    4.88  2.97  1.00 11.00 10.00
## sym2         14 20 27.65  9.07  27.00   27.75 11.12 13.00 43.00 30.00
##             skew kurtosis   se
## subject     0.00    -1.38 1.32
## condition*   NaN      NaN 0.00
## vermem1    -0.79    -0.70 1.60
## vismem1     0.45    -0.72 1.80
## vms1       -0.13    -0.78 0.81
## rt1         1.38     2.41 0.04
## ic1        -0.39    -0.81 0.37
## sym1        3.82    13.29 0.05
## vermem2     0.07    -1.24 2.21
## vismem2    -0.27    -1.26 1.87
## vms2        0.77    -0.57 2.24
## rt2         1.09    -0.10 0.05
## ic2         0.39    -0.28 0.57
## sym2       -0.11    -1.25 2.03
## -------------------------------------------------------- 
## group: control
##            vars  n  mean   sd median trimmed  mad   min   max range  skew
## subject       1 20 10.50 5.92  10.50   10.50 7.41  1.00 20.00 19.00  0.00
## condition*    2 20  2.00 0.00   2.00    2.00 0.00  2.00  2.00  0.00   NaN
## vermem1       3 20 89.85 5.82  90.00   90.31 7.41 78.00 98.00 20.00 -0.41
## vismem1       4 20 75.00 9.34  77.00   75.50 9.64 59.00 88.00 29.00 -0.46
## vms1          5 20 34.86 4.09  34.39   34.85 4.92 27.36 41.87 14.51  0.09
## rt1           6 20  0.67 0.13   0.66    0.67 0.13  0.42  1.00  0.58  0.47
## ic1           7 20  8.00 2.41   7.50    8.12 2.22  2.00 12.00 10.00 -0.41
## sym1          8 20  0.05 0.22   0.00    0.00 0.00  0.00  1.00  1.00  3.82
## vermem2       9 20 89.95 4.36  90.50   90.06 5.19 81.00 97.00 16.00 -0.25
## vismem2      10 20 74.60 7.76  74.50   75.00 8.15 60.00 86.00 26.00 -0.23
## vms2         11 20 33.40 6.44  34.54   33.52 6.30 20.15 44.28 24.13 -0.25
## rt2          12 20  0.57 0.16   0.56    0.57 0.13  0.19  0.90  0.71 -0.16
## ic2          13 20  8.50 2.31   9.00    8.69 1.48  3.00 12.00  9.00 -0.73
## sym2         14 20  0.10 0.31   0.00    0.00 0.00  0.00  1.00  1.00  2.47
##            kurtosis   se
## subject       -1.38 1.32
## condition*      NaN 0.00
## vermem1       -0.87 1.30
## vismem1       -1.27 2.09
## vms1          -1.19 0.91
## rt1           -0.02 0.03
## ic1           -0.17 0.54
## sym1          13.29 0.05
## vermem2       -1.02 0.97
## vismem2       -1.11 1.73
## vms2          -0.77 1.44
## rt2            0.06 0.04
## ic2           -0.32 0.52
## sym2           4.32 0.07</code></pre>
<p>Сделаем 2 подвыборки: контроль(control) и контуженные(concussed)</p>
<pre class="r"><code>control &lt;- subset(impact, condition==&quot;control&quot;)
concussed &lt;- subset(impact, condition==&quot;concussed&quot;)</code></pre>
<p>Посчитаем коэффициенты коррелляции для каждой подвыборки.</p>
<pre class="r"><code>controlcorr &lt;- round(cor(control$vismem2,control$vermem2),2)
concussedcorr &lt;- round(cor(concussed$vismem2,concussed$vermem2),2)</code></pre>
<p>Выведем все значения коэффициентов корелляции одновременно</p>
<pre class="r"><code>correlations &lt;- cbind(entirecorr, controlcorr, concussedcorr)
correlations</code></pre>
<pre><code>##      entirecorr controlcorr concussedcorr
## [1,]       0.45        0.37          0.35</code></pre>
</div>
<div id="-.-" class="section level2">
<h2>Линейная регрессия. Теория</h2>
<p>В качестве примера рассмотрим систолическое кровяное давление у людей (выражается в мм ртутного столба). Очевидно, что уровень кровяного давления не может быть одинаковым у всех людей – при обследовании случайно сформированной выборки мы почти всегда будем наблюдать определенный разброс значений этой переменной, хотя некоторые значения будут встречаться чаше других. Сформируем выборку возможного распределения 100 значений давления крови, (не будем пока уточнять механизм получения данных и предположим, что это – реальные измерения у реальных случайно отобранных людей, различающихся по возрасту, полу, массе тела и, возможно, каким-то другим характеристикам):</p>
<pre class="r"><code>y &lt;- c( 109.14, 117.55, 106.76, 115.26, 117.13, 125.39, 121.03, 114.03, 124.83, 113.92, 122.04, 109.41, 131.61, 103.93, 116.64, 117.06, 111.73, 120.41, 112.98, 101.20, 120.19, 128.53, 120.14, 108.70, 130.77, 110.16, 129.07, 123.46, 130.02, 130.31, 135.06, 129.17, 137.08, 107.62, 139.77, 121.47, 130.95, 138.15, 114.31, 134.58, 135.86, 138.49, 110.01, 127.80, 122.57, 136.99, 139.53, 127.34, 132.26, 120.85, 124.99, 133.36, 142.46, 123.58, 145.05, 127.83, 140.42, 149.64, 151.01, 135.69, 138.25, 127.24, 135.55, 142.76, 146.67, 146.33, 137.00, 145.00, 143.98, 143.81, 159.92, 160.97, 157.45, 145.68, 129.98, 137.45, 151.22, 136.10, 150.60, 148.79, 167.93, 160.85, 146.28, 145.97, 135.59, 156.62, 153.12, 165.96, 160.94, 168.87, 167.64, 154.64, 152.46, 149.03, 159.56, 149.31, 153.56, 170.87, 163.52, 150.97)

c(mean(y), sd(y)) # среднее значение и станд. отклонение</code></pre>
<pre><code>## [1] 135.15730  16.96017</code></pre>
<pre class="r"><code>shapiro.test(y)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  y
## W = 0.98263, p-value = 0.2121</code></pre>
<pre class="r"><code>library(ggplot2) # графическое изображение распределения данных</code></pre>
<pre><code>## 
## Attaching package: &#39;ggplot2&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:psych&#39;:
## 
##     %+%, alpha</code></pre>
<pre class="r"><code>ggplot(data = data.frame(y), aes(x = y)) + geom_histogram() +
ylab(&quot;Частота&quot;) + xlab(&quot;Давление, мм рт. ст.&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Греческие буквы μ и σ обозначают истинные (также “генеральные”) параметры модели, которые, как правило, нам неизвестны. Тем не менее, мы можем оценить значения параметров по соответствующим выборочным статистикам. Так, в случае представленных выше 100 значений систолического кровяного давления выборочные среднее значение и стандартное отклонение составляют 135.16 мм рт. ст. и 16.96 мм рт. ст. соответственно. Допуская, что данные действительно происходят из нормально распределенной генеральной совокупности, мы можем записать нашу модель в виде yi ~ N(135.16, 16.96). Эту модель можно использовать для предсказания давления крови, однако для всех людей предсказанное значение окажется одинаковым и будет равно μ.Обычным способом записи этой модели является следующий: <span class="math inline">\(y{i} = 135.16 + \epsilon{i}\)</span> , где ei – это остатки модели, имеющие нормальное распределение со средним значением 0 и стандартным отклонением 16.96: ei ~ N(0, 16.96). Остатки рассчитываются как разница между реально наблюдаемыми значениями переменной Y и значениями, предсказанными моделью (в рассматриваемом примере ei = yi - 135.16). С другой стороны эта запись представляет собой ни что иное, как линейную регрессионную модель, у которой нет ни одного предиктора, и которую часто называют «нуль-моделью» или «нулевой моделью» (англ. null models).</p>
<div id="-------------------.----------simulation-..-----------------------." class="section level4">
<h4>В сущности, статистическая модель – это упрощенное математическое представление процесса, который, как мы полагаем, привел к генерации наблюдаемых значений изучаемой переменной. Это значит, что мы можем использовать модель для симуляции (simulation) – т.е. процедуры, имитирующей моделируемый процесс и позволяющей тем самым искусственно генерировать новые значения изучаемой переменной, которые, как мы надеемся, будут обладать свойствами реальных данных.</h4>
<p>Новые данные на основе этой простой модели можно легко сгенерировать в R при помощи функции rnorm():</p>
<pre class="r"><code>set.seed(101) # для воспроизводимости результата
y.new.1 &lt;- rnorm(n = 100, mean = 135.16, sd = 16.96)

set.seed(101)
y.new.2 &lt;- 135.16 + rnorm(n = 100, mean = 0, sd = 16.96)</code></pre>
<p>Проверим, идентичны ли оба вектора?</p>
<pre class="r"><code>all(y.new.1 == y.new.2)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>Теперь необходимо вспомнить о том, что параметры нашей нулевой модели являются лишь точечными оценками истинных параметров, и что всегда будет присутствовать неопределенность в отношении того, насколько точны эти точечные выборочные оценки. В приведенных выше командах эта неопределенность не была учтена: при создании векторов y.new.1 и y.new.2 выборочные оценки среднего значения и стандартного отклонения кровяного давления рассматривались как параметры генеральной совокупности. В зависимости от поставленной задачи, такой подход может оказаться достаточным. Однако мы сделаем еще один шаг и постараемся учесть неопределенность в отношении точечных оценок параметров модели. При проведении имитаций воспользуемся функцией lm(), которая предназначена для подгонки линейных регрессионных моделей. Ничего удивительного здесь нет – ведь мы уже знаем, что нашу простую модель кровяного давления можно рассматривать как линейную регрессионную модель, у которой нет ни одного предиктора:</p>
<pre class="r"><code>y.lm &lt;- lm(y ~ 1) # формула для оценки только свободного члена
summary(y.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ 1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -33.957 -13.260   0.413  12.043  35.713 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  135.157      1.696   79.69   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 16.96 on 99 degrees of freedom</code></pre>
<p>Как следует из приведенных результатов, свободный член подогнанной модели (Intercept) в точности совпадает со средним значением данных (135.16 мм рт. ст.), а стандартное отклонение остатков модели (Residual standard error) совпадает со стандартным отклонением этих данных (16.96 мм рт. ст.). Важно, однако, что мы при этом вычислили также оценку стандартной ошибки среднего значения, равную 1.696 (см. столбец Std. Error на пересечении со строкой (Intercept)). По определению, стандартная ошибка параметра – это стандартное отклонение <span class="math display">\[нормального\]</span> распределения значений этого параметра, рассчитанных по выборкам одинакового размера из той же генеральной совокупности. Мы можем использовать это обстоятельство для учета неопределенности в отношении точечных оценок параметров модели при порождении новых данных. Так, зная выборочные оценки параметров и их стандартные ошибки, мы можем: а) сгенерировать несколько возможных значений этих параметров (т.е. составить несколько реализаций той же модели, варьируя значения параметров) и б) сгенерировать новые данные на основе каждой из этих альтернативных реализаций модели.</p>
<pre class="r"><code>library(arm)</code></pre>
<pre><code>## Loading required package: MASS</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## Loading required package: lme4</code></pre>
<pre><code>## Warning: package &#39;lme4&#39; was built under R version 3.5.2</code></pre>
<pre><code>## 
## arm (Version 1.10-1, built: 2018-4-12)</code></pre>
<pre><code>## Working directory is /Users/alex-mac-lab/Desktop/EcologyModeling.github.io</code></pre>
<pre><code>## 
## Attaching package: &#39;arm&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:psych&#39;:
## 
##     logit, rescale, sim</code></pre>
<pre class="r"><code>set.seed(102) # для воспроизводимости результата
y.sim &lt;- sim(y.lm, 5)</code></pre>
<p>y.sim - объект класса S4, который содержит слоты coef (коэффициенты модели) и sigma (станд. отклонения остатков модели):</p>
<pre class="r"><code>str(y.sim)</code></pre>
<pre><code>## Formal class &#39;sim&#39; [package &quot;arm&quot;] with 2 slots
##   ..@ coef : num [1:5, 1] 136 134 137 136 137
##   .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. ..$ : NULL
##   .. .. ..$ : chr &quot;(Intercept)&quot;
##   ..@ sigma: num [1:5] 16.8 18.9 17.3 16.7 15</code></pre>
<p>Извлекаем альтернативные реализации среднего из y.sim:</p>
<pre class="r"><code>y.sim@coef</code></pre>
<pre><code>##      (Intercept)
## [1,]    136.4780
## [2,]    134.3288
## [3,]    136.7079
## [4,]    136.0775
## [5,]    137.3250</code></pre>
<p>Извлекаем альтернативные реализации ст.отклонений остатков:</p>
<pre class="r"><code>y.sim@sigma</code></pre>
<pre><code>## [1] 16.82947 18.87039 17.30262 16.74308 15.00630</code></pre>
<p>Конечно, 5 реализаций модели – это совершенно недостаточно, чтобы сделать какие-либо убедительные выводы. Увеличим это число до 1000:</p>
<pre class="r"><code>set.seed(102) # для воспроизводимости результата
y.sim &lt;- sim(y.lm, 1000)</code></pre>
<p>Инициализация пустой матрицы, в которой мы будем сохранять данные, сгенерированные на основе 1000 альтернативных реализаций модели:</p>
<pre class="r"><code>y.rep &lt;- array(NA, c(1000, 100))
# Заполняем матрицу y.rep имитированными данными:
for(s in 1:1000){
y.rep[s, ] &lt;- rnorm(100, y.sim@coef[s], y.sim@sigma[s])
}</code></pre>
<p>Чтобы лучше понять, что мы только что сделали, изобразим гистограммы выборочных распределений значений кровяного давления, сгенерированных на основе, например, первых 12 реализаций нулевой модели:</p>
<pre class="r"><code>par(mfrow = c(5, 4), mar = c(2, 2, 1, 1))
for(s in 1: 12){ hist(y.rep[s, ], xlab = &quot;&quot;, ylab = &quot;&quot;,
breaks = 20, main = &quot;&quot;)}</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<p>Рассчитаем интерквартильный размах (ИКР) для каждого имитированного набора данных и сравним полученное распределение из 1000 значений с ИКР реальных данных. Для расчета ИКР в R служит функция IQR():</p>
<pre class="r"><code>test.IQR &lt;- apply(y.rep, MARGIN = 1, FUN = IQR)</code></pre>
<p>Выведем гистограмму значений ИКР, рассчитанных для каждого из 1000 имитированных распределений кровяного давления. Вертикальной синей линией покажем ИКР для реально наблюдаемых значений кровяного давления:</p>
<pre class="r"><code>hist(test.IQR, xlim = range(IQR(y), test.IQR), main = &quot;ИКР&quot;, xlab = &quot;&quot;, ylab = &quot;Частота&quot;, breaks = 20) 
lines(rep(IQR(y), 2), c(0, 100), col = &quot;blue&quot;, lwd = 4)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>На приведенном рисунке хорошо видно, что значения ИКР для имитированных данных систематически занижены по сравнению с реальными данными. Это свидетельствует о том, что нулевая модель в целом недооценивает уровень вариации реальных значений кровяного давления. Причиной этому может быть то, что мы не учитываем воздействие на кровяное давление каких-либо важных факторов (например, возраст, пол, диета, состояние здоровья, и т.п.). Рассмотрим, как можно расширить нашу нулевую модель, добавив в нее один из таких факторов.</p>
<p>Предположим, что помимо кровяного давления мы также измеряли у каждого испытуемого его/ее возраст (в годах). Покажем графически связь между возрастом и систолическим кровяным давлением. Для визуализации тренда в данных добавим линию регрессии синего цвета:</p>
<pre class="r"><code># Значения возраста:
x &lt;- rep(seq(16, 65, 1), each = 2)
# Объединяем значения возраста и давления крови в одну таблицу
Data &lt;- data.frame(Age = x, BP = y)
ggplot(data = Data, aes(x = Age, BP)) + geom_point() +
geom_smooth(method = &quot;lm&quot;, se = FALSE) +
geom_rug(color = &quot;gray70&quot;, sides = &quot;tr&quot;) +
ylab(&quot;Частота&quot;) + xlab(&quot;Возраст, лет&quot;)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>Из графика видно, что между давлением крови и возрастом существует выраженная линейная зависимость: несмотря на определенную вариацию наблюдений, по мере увеличения возраста давление в среднем также возрастает. Мы можем учесть это систематическое изменение среднего кровяного давления, добавив возраст (Age) в нашу нулевую модель: <span class="math inline">\(y{i}=N\big(\beta+\beta{i}\times Age{i},\sigma\big)\)</span>,</p>
<pre class="r"><code>summary(lm(BP ~ Age, data = Data))</code></pre>
<pre><code>## 
## Call:
## lm(formula = BP ~ Age, data = Data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -21.6644  -6.2491   0.0072   6.3101  17.3484 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 94.85498    2.66731   35.56   &lt;2e-16 ***
## Age          0.99512    0.06204   16.04   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.953 on 98 degrees of freedom
## Multiple R-squared:  0.7242, Adjusted R-squared:  0.7214 
## F-statistic: 257.3 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Согласно полученным результатам, модель кровяного давления можно записать как <span class="math inline">\(y{i}=N\big(94.853+0.995\times Age{i}, 8.953\big)\)</span> или <span class="math inline">\(y{i}=94.853+0.995\times Age{i} + \epsilon{i}, \epsilon{i} = N\big(0,8.953\big)\)</span></p>
<p>Графически эта модель изображена выше на рисунке в виде линии тренда. Обратите внимание: помимо высокой значимости параметров подогнанной модели (р &lt;&lt; 0.001 в обоих случаях), стандартное отклонение остатков составляет 8.853, что почти в 2 раза меньше, чем у нулевой модели (16.96). Это указывает на то, что модель, включающая возраст как предиктор, гораздо лучше описывает вариацию значений кровяного давления у 100 обследованных испытуемых, чем наша исходная модель без параметра.</p>
<p>Это заключение подтверждается тем, что в результате выполнения имитаций, аналогичных описанным выше, значение интерквартильного размаха для исходных данных располагается в центре распределения имитированных значений ИКР, указывая на отсутствие систематических различий между имитированными и наблюдаемыми данными. Код на языке R и полученную гистограмму мы здесь не приводим, рекомендуя проделать вычисления самому читателю.</p>
<p>Теперь настало время раскрыть небольшой секрет: тот факт, что модель, включающая возраст, гораздо лучше описывает исходные данные, неудивителен, поскольку эти наблюдения были… сгенерированы на основе модели <span class="math inline">\(y{i}=97.078+0.949\times Age{i} + \epsilon{i}, \epsilon{i} = N\big(0,9.563\big)\)</span> следующим образом:</p>
<pre class="r"><code>set.seed(101)
y &lt;- rnorm(100, mean = 97.078 + 0.949*x, 9.563)</code></pre>
<p>Последняя модель, придуманная в целях демонстрации обсуждаемых принципов, была использована в качестве “истинной” (англ. true model) в том смысле, что она описывала генеральную совокупность. Другими словами, мы предположили, что у нас была возможность одномоментно измерить давление у всех существующих людей и полученные данные описывались бы именно этой “истинной” моделью. В реальной ситуации ни структура (систематическая часть + остатки), ни значения параметров истинной модели исследователю, как правило, неизвестны.</p>
<p>Все, чем он располагает – это наборы экспериментальных данных, часто недостаточно репрезентативных и сильно “зашумленных”. Имея эти данные и хорошее понимание изучаемого явления (в смысле того, какие предикторы считать достаточно важными для рассмотрения), исследователь может только надеяться приблизиться к структуре истинной модели и оценить ее параметры с определенной точностью. К сожалению, такой успех гарантирован далеко не всегда.</p>
</div>
</div>
<div id="-.-" class="section level2">
<h2>Линейная регрессия. Практика</h2>
<pre class="r"><code>library(ggplot2)
library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:MASS&#39;:
## 
##     select</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>options(stringsAsFactors = FALSE)</code></pre>
<p>Загрузим данные сравнения достатка и роста человека и ряда других демографических характеристик от 1379 человек, которые были собранны в 1994 году. Это симулированные данные, основанные на реальных данных, собранных Гельманом и Хиллом.</p>
<pre class="r"><code>wages &lt;- read.csv(&quot;https://dl.dropboxusercontent.com/s/oq4dc134y8xdyce/wages.csv?dl=0&quot;)

tbl_df(wages)</code></pre>
<pre><code>## # A tibble: 1,379 x 6
##      earn height sex    race        ed   age
##     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;int&gt; &lt;int&gt;
##  1 79571.   73.9 male   white       16    49
##  2 96397.   66.2 female white       16    62
##  3 48711.   63.8 female white       16    33
##  4 80478.   63.2 female other       16    95
##  5 82089.   63.1 female white       17    43
##  6 15313.   64.5 female white       15    30
##  7 47104.   61.5 female white       12    53
##  8 50960.   73.3 male   white       17    50
##  9  3213.   72.2 male   hispanic    15    25
## 10 42997.   72.4 male   white       12    30
## # … with 1,369 more rows</code></pre>
<p>Еще один набор данных пытается проверить наличие связи между климатом и преступностью в различных штатах США.</p>
<pre class="r"><code>crime &lt;- read.csv(&quot;https://dl.dropboxusercontent.com/s/cecck1nuo217zy1/crime.csv?dl=0&quot;)

tbl_df(crime)</code></pre>
<pre><code>## # A tibble: 48 x 5
##    state       abbr    low murder tc2009
##    &lt;chr&gt;       &lt;chr&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1 Alabama     AL      -27    7.1  4338.
##  2 Alaska      AK      -80    3.2  3567.
##  3 Arizona     AZ      -40    5.5  3725.
##  4 Arkansas    AR      -29    6.3  4415.
##  5 California  CA      -45    5.4  3202.
##  6 Colorado    CO      -61    3.2  3024.
##  7 Connecticut CT      -32    3    2646.
##  8 Delaware    DE      -17    4.6  3997.
##  9 Florida     FL       -2    5.5  4454.
## 10 Georgia     GA      -17    6    4181.
## # … with 38 more rows</code></pre>
<p>Вы уже имеете общее представление о регресии и о некотором уравнении <span class="math inline">\(y{i}=N\big(\alpha+\beta{i}x{i}+\sigma\big)\)</span>, которое его в общем виде описывает. На самом деле, что не сложно заметить из того, что зависимость линейная, это уравнение линейной регрессии. Это самый простой из всех возможных вариантов, но потому и самый понятный. Поэтому мы начнем с него.</p>
<p>В дальнейшем мы разберем другие варианты регресии, и даже если вам в вашем исследовании сразу ясно, что ваши данные не описываются линейной зависимостью,настоятельно рекомендуется начинаеть свое исследование именно с линейных зависимостей.</p>
<p>Т.к. зависимость линейная, то ее графическое отображение на графике данных должно быть прямой, при чем эта прямая должна проходить через основной массив данных. Довольно очевидно, что через практически любой большой набор данных помещенных на график можно провести множество прямых, которые будут в той или иной мере описывать зависимость величин друг от друга. И встает вопрос каким образом выбрать ту самую прямую, которая будет описывать наши данные наилучшим образом.</p>
<p>В статистике приянто считать наиболее подходящей такую прямую, сумма квадратов остатков(residuals) которой будет минимальной. Под остатками понимают расстояние по вертикали от каждой точки данных до ближайшей точки прямой или <span class="math inline">\(Residuals=y{i}-f\big(x{i}\big)\)</span>, другое их название - отклонения. Т.к. каждый остаток может быть отличным по знаку, а нас интересует абсолютное значение всех остатков, т.к. каждый из них по сути характеризует точность модели, то суммируются не сами остатки а их квадраты. Таким образом итоговая результирующая качество модели величиная будет называться сумма квадратов отклонений(RSS) и будет иметь вид <span class="math inline">\(RSS=\Sigma\big(y{i}-f\big(x{i}\big)\big)^{2}\)</span></p>
<p>Очевидно, что в R уже существует готовое решения для подбора коэффициентов прямой, которые для приведенных данных дадут минимальную сумму квадратов отклонений. Меж тем, как и в любой другой задаче по программированию, ваша роль наиболее точно “объяснить” языку, что вы от него хотите.</p>
<p>Для получения линейных регрессионных уравнений в R существует функция lm. Она входит в большую семью функций применяемых для моделирования и использует аналогичный им синтаксис.</p>
<pre class="html"><code></code></pre>
<table>
<colgroup>
<col width="25%" />
<col width="27%" />
<col width="30%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">
переменная для хранения модели
</th>
<th align="left">
Функция инициации линейной модели
</th>
<th align="left">
Основная формула: отклик ~ показатели
</th>
<th align="left">
Таблица с данными
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">
mod
</td>
<td align="left">
= lm(
</td>
<td align="left">
tc2009 ~ low,
</td>
<td align="left">
data = crime)
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>mod = lm(tc2009 ~ low, data = crime)</code></pre>
<p>В R существует особый класс данных который называется “формулы”, созданный для описания зависимостей между объектами. Для того чтобы создать подобную зависимость в R используется символ тильда - ~</p>
<pre class="r"><code>tc2009 ~ low</code></pre>
<pre><code>## tc2009 ~ low</code></pre>
<pre class="r"><code>class(tc2009 ~ low)</code></pre>
<pre><code>## [1] &quot;formula&quot;</code></pre>
<p>По сути запись y ~ x, в R равносильна математической записи <span class="math inline">\(y{i}=N\big(\alpha+\beta{i} x{i}+\sigma\big)\)</span>. Для вас, как пользователя важно всегда помнить что описываемая или зависимая переменная всегда находится в подобной записи слева, т.е. “зависимая переменная” ~ “независимая переменная”. Или для случая y ~ x : зависимость y от x, но ни как не наоборот.</p>
<p>Как уже упоминалось ранее подобный синтаксис характерен не только для функции lm. В семейство подобных ей функций входят lmer,lme,rlm,glm,gam и др, часть из которых мы рассмотрим чуть позже.</p>
<p>Вернемся к нашей модели, которая пытается описать зависимость количества преступлений в 2009 году от минимально наблюдаемой температуры на данной территори за рассматриваемое время. Для того, чтобы увидеть, какие коэффициенты нам рассчитал R, обратимся к содержимому модели этого объекта - mod</p>
<pre class="r"><code>mod</code></pre>
<pre><code>## 
## Call:
## lm(formula = tc2009 ~ low, data = crime)
## 
## Coefficients:
## (Intercept)          low  
##     4256.86        21.65</code></pre>
<p>На самом деле в объекте модели содержится на много больше информации, чем показывается при стандартном выводе, поэтому объекты модели всегда лучше сохранять в отдельную переменную. Увидеть всю сложность объекта модели вы можете выполнив следующую команду:</p>
<pre class="r"><code>names(mod)</code></pre>
<pre><code>##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;</code></pre>
<div id="---" class="section level3">
<h3>Получение данных из модели</h3>
<p>Существует стандартный подход при работе с моделями в R, кратко он описывается хранение и исследование. Суть его сводится к двум простым действиям - сохранению объекта модели в памяти под видом переменной и выполнения ряда функций на этом объекте, для получения данных по исследованию функции объекта.</p>
<p>К подобным функциям относятся три следующие функции, которые предоставляют минимально необходимый функционал для исследования функций.</p>
<p>Вы уже знакомы с функцией summary, которая предоставляет нам общую информацию об объекте, в данном случае мы получим общую информацию по модели:</p>
<pre class="r"><code>summary(mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = tc2009 ~ low, data = crime)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1134.36  -647.13    98.03   533.62  1344.30 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4256.86     233.44  18.236  &lt; 2e-16 ***
## low            21.65       5.33   4.061 0.000188 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 649.9 on 46 degrees of freedom
## Multiple R-squared:  0.2639, Adjusted R-squared:  0.2479 
## F-statistic: 16.49 on 1 and 46 DF,  p-value: 0.000188</code></pre>
<p>Функция predict() (предсказание) рассчитывает значения интересующей вас переменной(столбца в таблице) для каждого ее значения. Т.е. для всех уже имеющихся значений вашей переменной будет посчитано значения этой переменной исходя из вашей модели, таким образом вы сможете узнать на сколько предсказываемые вашей моделью значения расходятся с реальными данными.</p>
<pre class="r"><code>predict(mod)</code></pre>
<pre><code>##        1        2        3        4        5        6        7        8 
## 3672.386 2525.082 3390.972 3629.091 3282.735 2936.379 3564.150 3888.858 
##        9       10       11       12       13       14       15       16 
## 4213.567 3888.858 4516.629 2958.027 3477.561 3239.441 3390.972 3455.913 
##       17       18       19       20       21       22       23       24 
## 3910.506 3217.794 3390.972 3499.208 3152.852 3845.564 3390.972 2741.554 
##       25       26       27       28       29       30       31       32 
## 3239.441 3174.499 3239.441 3520.855 3174.499 3131.205 3520.855 2958.027 
##       33       34       35       36       37       38       39       40 
## 3412.619 3672.386 3087.910 3347.677 3715.680 3845.564 3001.321 3564.150 
##       41       42       43       44       45       46       47       48 
## 3758.975 2763.201 3174.499 3607.444 3217.794 3455.913 3066.263 2828.143</code></pre>
<p>Функция resid() (остатки или отклонения) посчитает разницу между каждым имеющимся у вас значением моделируемой переменной и предсказанным вашей моделью результатом (то что вам считала предыдущая функция).</p>
<pre class="r"><code>resid(mod)</code></pre>
<pre><code>##            1            2            3            4            5 
##   665.114163  1042.018405   334.228411   786.308663   -81.135339 
##            6            7            8            9           10 
##    88.120658  -917.849587   107.941665   240.132917   291.741665 
##           11           12           13           14           15 
##  -573.828580  -702.426592   194.439412  -508.540840   270.428411 
##           16           17           18           19           20 
##  -631.913338   538.694415  -692.793590   397.428411  -704.407838 
##           21           22           23           24           25 
##   207.848160  -202.963835   531.928411    86.345907   -55.540840 
##           26           27           28           29           30 
##   590.500910  -786.540840 -1134.355088  1344.300910  -818.204590 
##           31           32           33           34           35 
##   622.844912  -725.826592   282.481162   475.814163   160.589909 
##           36           37           38           39           40 
##  -739.577089  -844.780336   716.636165  -975.121091   868.450413 
##           41           42           43           44           45 
##   749.625164   761.798657  -597.299090  -921.344087   866.106410 
##           46           47           48 
##  -418.513338  -193.962841     5.056907</code></pre>
</div>
<div id="--" class="section level3">
<h3>Интерпретируем данные моделей</h3>
<p>Как уже и говорилось ранее линейные модели наиболее примитивные, а потому лучше всего поддающиеся интерпретации <span class="math inline">\(y{i}=\alpha+\beta x+\epsilon\)</span></p>
<p><span class="math inline">\(\alpha\)</span> это значение нашей переменной при x равном 0.</p>
<p><span class="math inline">\(\beta\)</span> предполагаемое увеличение значения y вызванное увеличением x на одну единицу</p>
<p>Для получения коэфициентов вашей модели вы можете воспользоваться следующими абсолютно идентичными функциями:</p>
<pre class="r"><code>coef(mod)</code></pre>
<pre><code>## (Intercept)         low 
##  4256.86158    21.64725</code></pre>
<pre><code>## (Intercept)         low 
##  4256.86158    21.64725</code></pre>
<pre class="r"><code>coefficients(mod)</code></pre>
<pre><code>## (Intercept)         low 
##  4256.86158    21.64725</code></pre>
<pre><code>## (Intercept)         low 
##  4256.86158    21.64725</code></pre>
<p>Их выдача может показаться не очень ясной, но достаточно вспомнить, что <span class="math inline">\(\alpha\)</span> это точка, в которой прямая характеризующая нашу модель пересекает ось y и становится довольно очевидно, что представленное нам занчение Intercept не что иное, как коэффициент <span class="math inline">\(\alpha\)</span>. Ну оставшееся значение low это коэффициент <span class="math inline">\(\beta\)</span>.</p>
<p>Таким образом для нашей мделируемой перменной tc2009 значение при low = -10 составит 4256.86 + 21.6 * (-10) = 4040.86. Изменение переменной low на единицу приведет к изменению на 21.6 в переменной tc2009</p>
<p>Построим график зависимотси предсказываемых нашей функцией значений от независимой переменной low, воспользуемся для этого функцией predict()</p>
<pre class="r"><code>qplot(low, predict(mod), data = crime, geom = &quot;line&quot;)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-58-1.png" width="672" /></p>
<p>Логично, что для построения этого графика мы использовали geom = “line”, что равнозначно использованию <code>+geom_line()</code>, т.к. наша зависимость линейна и это именно тот тип графика, коорый мы хотим получить. Меж тем, ggplot позволяет нам построить модель модел прямо при создании графика и, как ни странно мы уже делали это на предыдущих занятиях. Для этого существует уже хорошо известная нам геометрия <code>geom_smooth()</code>. Правда для того чтобы получить аналогичный предыдущему график, мы должны явно объявить функции геометри тот тип, что мы успользовали, т.е. <code>geom_smooth(method=lm)</code>, соответственно ggplot будет знать что наша модель будет иметь оббщий вид <code>lm(x~y, crime)</code>. Добавление параметра <code>se=FALSE</code> уберет доверительные интервалы, которые чаще вводят в заблуждение, чем помогают.</p>
<pre class="r"><code>qplot(low, tc2009, data = crime) + 
  geom_smooth(method = lm)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<pre class="r"><code>qplot(low, tc2009, data = crime) +
  geom_smooth(se = FALSE, method = lm)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<p><strong><em>Важно</em></strong>. По умолчанию R пытается добавить <span class="math inline">\(\alpha\)</span> в каждую линейную модель . Т.е. R строит модель исходя из того, что <span class="math inline">\(\alpha\)</span> не равна 0. Меж тем мы можем заставить R строить модель исходя из того, что <span class="math inline">\(\alpha\)</span> равна 0. Т.е. график нашей функйии должен обязательно проходить через координаты (0, 0).</p>
<p>Для того чтобы R исходил из того, что <span class="math inline">\(\alpha\)</span> равна 0 в формулу модели нужно добавить 0 или -1. Добавление к формуле +1 заставляет R стоить модель исходя из того, что <span class="math inline">\(\alpha\)</span> не равна 0. Рассмотрим следующие примеры:</p>
<p>Включаем <span class="math inline">\(\alpha\)</span> в модель</p>
<pre class="r"><code>lm(tc2009 ~ 1 + low, data = crime)</code></pre>
<pre><code>## 
## Call:
## lm(formula = tc2009 ~ 1 + low, data = crime)
## 
## Coefficients:
## (Intercept)          low  
##     4256.86        21.65</code></pre>
<pre class="r"><code>lm(tc2009 ~ low, data = crime)</code></pre>
<pre><code>## 
## Call:
## lm(formula = tc2009 ~ low, data = crime)
## 
## Coefficients:
## (Intercept)          low  
##     4256.86        21.65</code></pre>
<pre class="r"><code>qplot(low, predict(lm(tc2009 ~ 1 + low, data = crime)), data = crime, geom = &quot;line&quot;)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-63-1.png" width="672" /></p>
<p>Исключаем <span class="math inline">\(\alpha\)</span> из модели</p>
<pre class="r"><code>lm(tc2009 ~ low - 1, data = crime)</code></pre>
<pre><code>## 
## Call:
## lm(formula = tc2009 ~ low - 1, data = crime)
## 
## Coefficients:
##    low  
## -67.36</code></pre>
<pre class="r"><code>lm(tc2009 ~ 0 + low, data = crime)</code></pre>
<pre><code>## 
## Call:
## lm(formula = tc2009 ~ 0 + low, data = crime)
## 
## Coefficients:
##    low  
## -67.36</code></pre>
<pre class="r"><code>qplot(low, predict(lm(tc2009 ~ low - 1, data = crime)), data = crime, geom = &quot;line&quot;)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-66-1.png" width="672" /></p>
<p>Как вы могли заметить включение или исключение $$$$ коренным образом меняет нашу модель. Поэтому к подобному приему стоит прибегать только в тех случаях когда вы точно уверены в том, что ваша функция проходит или не проходит через начало координат.</p>
<p>Давайте теперь воспользуемся другим набором данных, который мы уже успели загрузить - wages. Данная таблица содержит данные, которые были собраны для попытки описания зависимости заработка человека от его роста. Давайте построим модель, которая будет описывать такую зависимость и попытаемся интерпретировать результат.</p>
<pre class="r"><code>hmod &lt;- lm(earn ~ height, data = wages)
coef(hmod)</code></pre>
<pre><code>## (Intercept)      height 
## -126523.359    2387.196</code></pre>
<p>Давайте подставим полученные коэффициенты в общее уравнение линейной регрессии <span class="math inline">\(earn=\alpha+\beta\times height+\epsilon\)</span>. В результате мы получим следующее уравнение:</p>
<p><span class="math inline">\(earn=-126523.36+2387.20\times height+\epsilon\)</span></p>
<p>Давайте вспомним, что присутствующий в конце многочлена элемент <span class="math inline">\(\epsilon\)</span> является показателем того, что наша модель не модет быть абсолютной точной, а потому всегда присутствует отклонение от реальных данных. Все эти отклонения и представлены элементом <span class="math inline">\(\epsilon\)</span>. Т.к. мы не знаем ошибки для каждого конкретного значения, в представлении уравнения мы будем брать <span class="math inline">\(\epsilon\)</span> равным нулю, но при этом помнить, что отклонение существует.</p>
<p>Данные по росту представлены в дюймах. Поэтому для человека высотой 68 дюймов(1,72 метра) расчетная по данным нашей модели зарплата составит</p>
<p><span class="math inline">\(earn=-126523.36+2387.20\times 68+\epsilon\)</span></p>
<p><span class="math inline">\(earn=35806.24\)</span></p>
<p>Еще одним довольно простым выводом из нашей моедли будет то, что уведичение роста на 1 дюйм должно приводить к росту доходов на $2387.20 в год.</p>
<pre class="r"><code>qplot(height, earn, data = wages, alpha = I(1/4)) +
  geom_smooth(se = FALSE, method = lm) + theme_bw()</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-68-1.png" width="672" /></p>
<div id="---" class="section level4">
<h4>Давайте подведем небольшой итог</h4>
<p>Подгонка модели в R состоит из 3 этапов:</p>
<ol style="list-style-type: decimal">
<li><p>Описание отношений между интересующими нас переменными с помощью формул:<code>earn ~ height</code></p></li>
<li><p>Использование специальных формул для “подгонки”(создания) модели по заданной ранее формуле: <code>mod &lt;- lm(earn ~ height, data = wages)</code></p></li>
<li><p>Анализ полученного результата различными способами: <code>summary(mod)</code> <code>plot(mod)</code></p></li>
</ol>
</div>
</div>
</div>
<div id="----" class="section level2">
<h2>Анализ модели и статистические выводы</h2>
<p>Довольно очевидно, что модно получить модели описывающие связи между совершенно не связанными данными. Тогда перед нами встает вопрос того, а как мы можем быть уверены, что связь, которую нам “отыскала” модель существует и хоть сколько-нибудь точна. Наименьшая сумма квадратов отклонений, конечно хороший показатель, но надо понимать, что этот показатель ничего нам не гарантирует.</p>
<p>Если вернуться от общего описания к более статистическому, модель, которую мы получаем благодаря R, представляет только тот небольшой объем данных, что у нас есть, или выборку. Нас же всегда интересует модель, которая описывает генеральную совокупность. Таким образом, больше всего в полученной нами модели нас будет интересовать то, на сколько она отличается от модели генеральной совокупности.</p>
<p>Давайте загрузим данные которые содержат 100 совершенно случайно отобранных значений из предыдущего наббра данных и построим график полученных данных.</p>
<pre class="r"><code>w1 &lt;- read.csv(&quot;https://dl.dropboxusercontent.com/s/qnybbt5sxiedsd7/w1.csv?dl=0&quot;)
qplot(height, earn, data = w1) +  geom_smooth(method = lm, se = F)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
<p>Построим аналогичный график для всего объема доступных данных.</p>
<pre class="r"><code>qplot(height, earn, data = wages) +  geom_smooth(method = lm, se = F)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-70-1.png" width="672" /></p>
<p>Давайте зададимся вопросом о том, а что будет если мы возьмем другую выборку? Будет ли <span class="math inline">\(\beta\)</span> = <span class="math inline">\(\beta\)</span> если мы возьмем другую выборку? Скорее всего нет. Будет ли <span class="math inline">\(\beta\)</span> = 0, если мы возьмем другую выборку? Возможно.</p>
<p>Следует сделать важное отступление. Значение <span class="math inline">\(\beta\)</span> = 0 сильно отличается по важности для нас от всех остальных значений, т.к. оно будет значить, что изменение независимой переменной не приводит к изменению зависимой переменной. Другими словами, оно будет значить, что у нас нет связи между нашими перемеными.</p>
<p>А каков инетрвал в котором лежат все возможные значения <span class="math inline">\(\beta\)</span>?</p>
<p>Для ответа на этот вопрос есть два инструментальных подхода - подходы для рассуждений о неопределенности параметров модели</p>
<ul>
<li>параметрическая статистика</li>
<li>непараметрическая статистика (бутстрапирование или самонастройка)</li>
</ul>
<div id="-" class="section level3">
<h3>Параметрическая статистика</h3>
<p>Если модель удовлетворяет ряду предположений, то существует возможность вычислить вероятность наблюдения определнной β, даже в то время как истинная β=0. Если вы вспомните курс статистики, то поймете, что мы просто дургими словами сформулировали нулевую гипотезу для регрессионого анализа. Которая состояла в том, что генеральный угловой коэффициент линии регрессии β равен нулю.</p>
<p>Для того, чтобы разобраться в этом глубже, давайте рассмотрим конкретный пример. Для этого вернемся к модели зависимости заработка от роста: <code>hmod</code>:</p>
<pre class="r"><code>summary(hmod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = earn ~ height, data = wages)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -47903 -19744  -5184  11642 276796 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -126523      14076  -8.989   &lt;2e-16 ***
## height          2387        211  11.312   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 29910 on 1377 degrees of freedom
## Multiple R-squared:  0.08503,    Adjusted R-squared:  0.08437 
## F-statistic:   128 on 1 and 1377 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Рассмотрим подробнее предложенную нам выдачу. <code>#      Estimate Std. Error t value   Pr(&gt;|t|)</code> `<code># height   2387        211   11.312    &lt;2e-16 ***</code></p>
<p>Вероятность того, что <span class="math inline">\(\beta_{height} &gt;= 2387\)</span> при условии, что истинная <span class="math inline">\(\beta=0\)</span> в представленном нам примере практически равна 2е-16 (практически 0). Или другими словами, вероятность нулевой гипотезы равна предельно малой ввеличине, а значит мы можем сказать, что <span class="math inline">\(\beta\)</span> не равен нулю.</p>
<p>Если быть совсем точными, низки p-значения ( &lt; 0.05), могут быть результатом следующих событий 1. У нас крайне не репрезентативная выборка 2. Истинная β генеральной совокупности не равна 0 3. Наша модель в принципе не корректна</p>
<p>Возникает логичный вопрос, но если мы доказали что β не ноль, то чему же она равна. К сожалению у нас нет других данных, кроме полученных от модели, поэтому наиболее правильным будет предположить, что β = 2387.</p>
<p>Заметим, однако, что найденное нами наиболее вероятное точечное значение β при повторных измерениях может оказаться иным. Чтобы охарактеризовать эту неопределенность, необходимо рассчитать доверительный интервал – не противоречащий имеющимся данным диапазон значений, в котором находится истинное значение нашей величины с определенной вероятностью (например, 95%). Ориентировочно оценить границы доверительного интервала можно, предположив, что примерно 95% всех значений распределения оценок β лежат в диапазоне ±2<span class="math inline">\(SE{\beta}\)</span> относительно его среднего значения, где <span class="math inline">\(SE{\beta}\)</span> – стандартная ошибка параметра β. Однако неопределенность имеется в отношении не только оценки параметра β, но и оценки его стандартного отклонения для соответствующего нормального распределения. Не углубляясь в детали, отметим, что в связи с этим обстоятельством более точные значения границ доверительного интервала дадут вычисления, основанные на свойствах t- распределения Стьюдента. Тогда границы 95%-го доверительного интервала для параметра β составят: <span class="math display">\[β ±  t_{0.975} SE{\beta} \]</span>,</p>
<p>где <span class="math inline">\(t_{0.975}\)</span> – 0.975-квантиль t-распределения с (n - p) числом степеней свободы, n – объем выборки, а p – число параметров модели.</p>
<p>Получить интервал для заданной точности можно следующей командой:</p>
<pre class="r"><code>confint(hmod, level = 0.95)</code></pre>
<pre><code>##                   2.5 %     97.5 %
## (Intercept) -154135.798 -98910.920
## height         1973.228   2801.163</code></pre>
<p>Еще раз, данные нам цифры означают, что мы можем с 95% вероятностью утверждать, что значение β находится в данном нам интервале от 1973.228 до 2801.163.</p>
<p>Расмотрим еще раз данные по связи между температурой и преступностью</p>
<pre class="r"><code>mod &lt;- lm(tc2009 ~ low, data = crime)
summary(mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = tc2009 ~ low, data = crime)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1134.36  -647.13    98.03   533.62  1344.30 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4256.86     233.44  18.236  &lt; 2e-16 ***
## low            21.65       5.33   4.061 0.000188 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 649.9 on 46 degrees of freedom
## Multiple R-squared:  0.2639, Adjusted R-squared:  0.2479 
## F-statistic: 16.49 on 1 and 46 DF,  p-value: 0.000188</code></pre>
<p>Как вы можете видеть, модель говорит нам, что существует достоверная связь между низкими температурами и уровнем преступности. С другой стороны, очень сложно себе представить какова реальная связь между низкими температурами и преступностью.</p>
<p>Этот пример должен вам напомнить о том, что низкие р значения не обязательно означают не нулевую <span class="math inline">\(\beta\)</span>. И в данном случае более верным будет предположить, что мы подобрали неверную модель или наша выборка крайне неудачна.</p>
<p>Какие же существуют способы сделать правильный вывод из полученных моделей? Давайте посмотрим на то как распределены наши данные построив графики, для двух таблиц, модели данных которых мы строили.</p>
<pre class="r"><code>qplot(low, tc2009, data = crime)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-74-1.png" width="672" /></p>
<pre class="r"><code>qplot(height, earn, data = wages)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-75-1.png" width="672" /></p>
<p>Первое, что сразу бросается в глаза, это то, что для первой модели линейная зависимость является вполне подходящим вариантом. А вот зависимость между переменными во второй таблице данных вряд ли является линейной.</p>
<p>В объекте содержащем модель есть данные для построения графиков по проверке ряда предположений. В первую очередь мы должны проверить предположение о нормальности распределения данных.</p>
<pre class="r"><code>plot(mod)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-76-1.png" width="672" /><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-76-2.png" width="672" /><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-76-3.png" width="672" /><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-76-4.png" width="672" /></p>
<p>Первый и третий графики - Residuals vs Fitted и Scale-Location показывают зависимость отклонений от предсказанных моделью значений. Если на графике можно проследить хоть какую-то зависимость, то это означает, что отклонения не случайны и существует еще какой-то фактор воздействующий на изучаемую зависимую переменную, а значит мы должны усложнить нашу модель.</p>
<p>Второй график Normal Q-Q показывает распределение отклонений по квантилям. Чем ближе распределение к линейному, тем больше шанс того, что наши отклонения распределены нормально.</p>
<p>С помощью последнего графика вы можете определиьт точки, которые сильно отличаются от остальных и тем самым приводят к сильным отклонениям в модели. На графике прерывной линией показана зона при выходе точек за пределы которой стоит обратить на них пристальное внимание. Если такие точки имеются, то следует создать альтернативный набор данных, без этих точек, построить новую модель для уже для альтернативного набора данных и выбрать лучшую.</p>
</div>
</div>
<div id="-" class="section level2">
<h2>Множественное сравнение</h2>
<p>До этого мы строили модели, используя только численные переменные. Давайте вспомним что у нас есть еще и категориальные значения называемые R факторами и рассмотрим следующий пример:</p>
<pre class="r"><code>rmod &lt;- lm(earn ~ race, data = wages)
coef(rmod)</code></pre>
<pre><code>##  (Intercept) racehispanic    raceother    racewhite 
##    28372.094    -2886.791     3905.320     4993.330</code></pre>
<p>Мы попытались посторрить линейную модель зависимости заработка от расы. Если мы посмотрим на коэффициенты, то результат будет довольно неожиданный. Во первых, были посчитаны коэффициенты для каждого уровня фактора, а во вторых, у нас представлены не все уровни, напрмер у нас нет коэффициента для уровня “black”.</p>
<p>Дело в том, что один из уровней переменной выбирается в качестве базового. Каждый последующий уровень получает некий номер в градации и для него расситывается отдельный коэффициент, которые показывает на сколько его коэффициент отличается от базового.</p>
<p>Т.к. мы не увидели коэффициента для черного населения, значит он и является базовым, т.е. 28372.09. Для испаноязычного населения итоговый коэффициент составит 28372.09 + -2886.79 = 25485.30. И для белого населения 28372.09 + 4993.33 = 33365.42</p>
<p>Т.к. итоговый показатель у испаноязычного населения самый низкий было бы логично сделать его базовым уровнем. Вы можете это сделать поменяв порядок уровней у фактора:</p>
<pre class="r"><code>wages$race &lt;- factor(wages$race, 
  levels = c(&quot;hispanic&quot;, &quot;white&quot;, &quot;black&quot;, &quot;other&quot;))
rmod2 &lt;- lm(earn ~ race, data = wages)
coef(rmod2)</code></pre>
<pre><code>## (Intercept)   racewhite   raceblack   raceother 
##   25485.303    7880.121    2886.791    6792.111</code></pre>
<p>Легко заметить, что не смотря на то, что значения коэффициентов поменялись, их результирующие значения остались прежними.</p>
<div id="anova" class="section level4">
<h4>ANOVA</h4>
<p>Давайте опять обратимся к вашим знаниям по статистике и задумаеся, а на что же похож регрессионый анализ для категориальных переменных? По сути в нем мы пытаемся сравнить различия между большой объединяющей группой и ее отдельными подгруппами, что очень похоже на дисперсионный анализ (ANOVA - Analysis of Variance). На самом деле это так и мы можем использовать данные дисперисонного анализа, применив команду anova() на нашу модель.</p>
<pre class="r"><code>anova(rmod2)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: earn
##             Df     Sum Sq    Mean Sq F value  Pr(&gt;F)  
## race         3 6.7924e+09 2264121503  2.3241 0.07328 .
## Residuals 1375 1.3395e+12  974196170                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Помимо дисперсионного анализа существует множество подобных ему тестов, которыми вы тоже можете воспользоваться:</p>
<table>
<thead>
<tr class="header">
<th>Функция</th>
<th>Тест</th>
<th>Статистика</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>lm</td>
<td>ANOVA</td>
<td>среднее</td>
</tr>
<tr class="even">
<td>aov</td>
<td>ANOVA</td>
<td>среднее</td>
</tr>
<tr class="odd">
<td>anova</td>
<td>ANOVA</td>
<td>среднее</td>
</tr>
<tr class="even">
<td>oneway.test</td>
<td>ANOVA для различных дисперсий</td>
<td>среднее</td>
</tr>
<tr class="odd">
<td>pairwise.t.test</td>
<td>t тест множетсва групп</td>
<td>среднее</td>
</tr>
<tr class="even">
<td>kruskal.test</td>
<td>Kruskal Wallis Rank Sum</td>
<td>сумма</td>
</tr>
<tr class="odd">
<td>friedman.test</td>
<td>Friedman Rank Sum</td>
<td>сумма</td>
</tr>
<tr class="even">
<td>fligner.test</td>
<td>Fligner-Killeen</td>
<td>дисперсия</td>
</tr>
<tr class="odd">
<td>bartlett.test</td>
<td>Bartlett test</td>
<td>дисперсия</td>
</tr>
</tbody>
</table>
<p>Давайте посмотрим зависимость заработка от пола. И существует ли статистически достоверная разница между зарплатами мужчи и женщин</p>
<pre class="r"><code>smod &lt;- lm(earn ~ sex, data = wages)
coef(smod)</code></pre>
<pre><code>## (Intercept)     sexmale 
##    24245.65    21747.48</code></pre>
<pre class="r"><code>wages$sex &lt;- factor(wages$sex, 
  levels = c(&quot;male&quot;, &quot;female&quot;))
smod &lt;- lm(earn ~ sex, data = wages)
coef(smod)</code></pre>
<pre><code>## (Intercept)   sexfemale 
##    45993.13   -21747.48</code></pre>
<p>Итак, если мы возьмем мужскую зарплату в качестве базовой, она составит 45993, а женская будет меньше ее на 21747. Разница оказалась колосальной, поэтому давайте проверим на сколько эти данные стаистически достоверны:</p>
<pre class="r"><code>anova(smod)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: earn
##             Df     Sum Sq    Mean Sq F value    Pr(&gt;F)    
## sex          1 1.5320e+11 1.5320e+11  176.81 &lt; 2.2e-16 ***
## Residuals 1377 1.1931e+12 8.6646e+08                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Pr(&gt;F) &lt; 2.2e-16 *** говорит нам о том, что вероятность нулевой гипотезы равна нулю, а значит рассчитанная нашей моделью огромная разница является статистически достоверной. Гистограмма зарплат еще раз подтверждает нам это:</p>
<pre class="r"><code>qplot(earn, data = wages, geom = &quot;density&quot;, color = sex) + theme_bw()</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-83-1.png" width="672" /></p>
<p>Построив аналогичный график для различных рас мы можем заметить, что разница между рассами не на столько принципиальная:</p>
<pre class="r"><code>qplot(earn, data = wages, geom = &quot;density&quot;, color = race) + theme_bw()</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-84-1.png" width="672" /></p>
</div>
</div>
<div id="---" class="section level2">
<h2>Оценка функций многих переменных</h2>
<p>До этого мы рассматривали зависимость одной переменной только от одной другой. Меж тем, R позволяет искать зависимость от неограниченного количества переменных. Напрмер построим модель зависимости заработка от роста</p>
<pre class="r"><code>m1 &lt;- lm(earn ~ height, data = wages)
coef(m1)</code></pre>
<pre><code>## (Intercept)      height 
## -126523.359    2387.196</code></pre>
<p>А вот уже следующий код позволяет нам описать зависимость заработка от возраста и пола.</p>
<pre class="r"><code>m2 &lt;- lm(earn ~ height + sex, data = wages)
coef(m2)</code></pre>
<pre><code>## (Intercept)      height   sexfemale 
##  -15605.703     879.424  -16874.158</code></pre>
<p>Второй коэффициент ожет быть интерпретирован как эффект от наличия женского пола …когда рост рассматривается неизменным. Первый коэффициент может быть интерпретирован как изменения заработка в зависимости от роста …при условии, что пол неизменен.</p>
<p>Следующий график демонстрирует две модели - зависимости заработка от роста для мужчин и женщин</p>
<pre class="r"><code>qplot(height, earn, data = wages, alpha = I(1/10), color = sex) + theme_bw() + geom_line(aes(y = predict(m2)))</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-87-1.png" width="672" /></p>
<p>Таким образом добавление дополнительной переменнйо по сути привело к разбиению нашей модели.</p>
<p>Обратимся к известному вам набору данный diamond и рассмотрим влияние типа огранки (cut) и количества карат в бриллианте на его стоимость:</p>
<pre class="r"><code>qplot(price, data = diamonds, color = cut, geom = &quot;density&quot;)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-88-1.png" width="672" /></p>
<p>Построим две модели, с учетом и без учета веса бриллианта в каратах:</p>
<pre class="r"><code>diamonds$cut &lt;- as.character(diamonds$cut)

d1 &lt;- lm(price ~ cut, data = diamonds)
coef(d1)</code></pre>
<pre><code>##  (Intercept)      cutGood     cutIdeal   cutPremium cutVery Good 
##    4358.7578    -429.8933    -901.2158     225.4999    -376.9979</code></pre>
<pre class="r"><code>d2 &lt;- lm(price ~ cut + carat, data = diamonds)
coef(d2)</code></pre>
<pre><code>##  (Intercept)      cutGood     cutIdeal   cutPremium cutVery Good 
##    -3875.470     1120.332     1800.924     1439.077     1510.135 
##        carat 
##     7871.082</code></pre>
<p>Если мы посмотрим на данные модели не учитывавшей вес бриллианта, мы увидим странную картину, когда стоимость бриллианта с идеальной агранкой сильно меньше, чем у бриллианта с хорошей и очень хорошей огранкой. Но если в модели учесть вес (а значит и размер) бриллианта, то все становится на свои места. И бриллианты с идеальной агранкой в этой модели стоят дороже, но с учетом их “каратности”.</p>
<p>Описанное выше прекрасно видно на следующем графике:</p>
<pre class="r"><code>qplot(carat, predict(d2), data = diamonds, color = cut, geom = &quot;line&quot;)</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-91-1.png" width="672" /></p>
<div id="----------------" class="section level4">
<h4>Подобный эффект от введения дополнительной переменной широко известен и даже имеет собственное имя - парадокс Симпсона</h4>
<p>Суть его состоит в том, что связь между двумя переменными может измениться, если учесть, третью, связанную с ними переменную.</p>
</div>
<div id="..----------" class="section level4">
<h4>Т.к. эта проблема хорошо известна, у нее существует и стандартное решение:</h4>
<p>Моделируйте каждый источник изменений в системе одновременно</p>
<p>Создадим новую модель, которая предсказывает заработок в зависимости от роста, пола, расы, образования и возраста.И попытаемся ответить на вопрос существует ли связь между высотой и заработком? А между полом и заработком?</p>
<pre class="r"><code>m3 &lt;- lm(earn ~ height + sex + race + ed + age, data = wages)
coef(m3)</code></pre>
<pre><code>## (Intercept)      height   sexfemale   racewhite   raceblack   raceother 
## -74354.1693    632.7391 -17552.5441   4592.7865   2086.0663   1708.3196 
##          ed         age 
##   4382.0853    287.4744</code></pre>
<p>Символ . используется в формуле, как обозначение всех остальных переменных. Т.е. мы можем описать такую же модель с помощью кода:</p>
<pre class="r"><code>lm(earn ~ height + sex + race + ed + age, data = wages)</code></pre>
<pre><code>## 
## Call:
## lm(formula = earn ~ height + sex + race + ed + age, data = wages)
## 
## Coefficients:
## (Intercept)       height    sexfemale    racewhite    raceblack  
##    -74354.2        632.7     -17552.5       4592.8       2086.1  
##   raceother           ed          age  
##      1708.3       4382.1        287.5</code></pre>
<pre class="r"><code>lm(earn ~ ., data = wages)</code></pre>
<pre><code>## 
## Call:
## lm(formula = earn ~ ., data = wages)
## 
## Coefficients:
## (Intercept)       height    sexfemale    racewhite    raceblack  
##    -74354.2        632.7     -17552.5       4592.8       2086.1  
##   raceother           ed          age  
##      1708.3       4382.1        287.5</code></pre>
<p>Подобную запись, с использованием знака . можно модифицировать отнимая от нее отдельные переменные:</p>
<pre class="r"><code>lm(earn ~ height + sex + race + ed, data = wages)</code></pre>
<pre><code>## 
## Call:
## lm(formula = earn ~ height + sex + race + ed, data = wages)
## 
## Coefficients:
## (Intercept)       height    sexfemale    racewhite    raceblack  
##    -46648.9        440.6     -18036.5       6128.5       2915.6  
##   raceother           ed  
##      3379.3       4159.8</code></pre>
<pre class="r"><code>lm(earn ~ . - age, data = wages)</code></pre>
<pre><code>## 
## Call:
## lm(formula = earn ~ . - age, data = wages)
## 
## Coefficients:
## (Intercept)       height    sexfemale    racewhite    raceblack  
##    -46648.9        440.6     -18036.5       6128.5       2915.6  
##   raceother           ed  
##      3379.3       4159.8</code></pre>
</div>
</div>
</div>
<div id="--" class="section level1">
<h1>Условия взаимодействия переменных</h1>
<p>До этого мы исходили из того, что каждая из независимых переменных не влияет на другую. Что, например очевидно не верно для пола и роста, т.к. средний рост женщин меньше. Для того, чтобы R учитывал при моделировании взаимодействие независимых переменных, мы должны будем добавить к формуле еще одну переменную, которая описывает взаимодействие этих переменных между собой. Так для вышеупомянутых роста и пола итоговая формула модели будет выглядеть так:</p>
<pre class="r"><code>m4 &lt;- lm(earn ~ height + sex + height:sex,   data = wages)
coef(m4)</code></pre>
<pre><code>##      (Intercept)           height        sexfemale height:sexfemale 
##      -42677.4003        1265.9167       30510.4336        -701.4065</code></pre>
<p>Что означают полученные коэффициенты? Для мужчин увеличение роста на 1 дюйм приведет к увеличению заработка на 1265.92. Для женщин увеличение роста на 1 дюйм приведете к увеличению заработка на 1265.92 + (-701.41) = 564.51.</p>
<p>Если мы построим графики двух предсказаний двух моделей, то сможем заметить, что у модели с учетом взамиодействия переменных прямые для мужчин и женщин перестали быть параллельны. Что означает, чтоизменение в росте у мужчин и женщин будет приводить к разному росту зарплат.</p>
<pre class="r"><code>qplot(height, earn, data = wages, alpha = I(1/10), color = sex) + theme_bw() + geom_line(aes(y = predict(lm(earn ~ height + sex,   data = wages))))</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-98-1.png" width="672" /></p>
<pre class="r"><code>qplot(height, earn, data = wages, alpha = I(1/10), color = sex) + theme_bw() + geom_line(aes(y = predict(m4)))</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-99-1.png" width="672" /></p>
<p>Итак, функция вида</p>
<pre class="r"><code>lm(earn ~ height + sex + height:sex, data = wages)</code></pre>
<pre><code>## 
## Call:
## lm(formula = earn ~ height + sex + height:sex, data = wages)
## 
## Coefficients:
##      (Intercept)            height         sexfemale  height:sexfemale  
##         -42677.4            1265.9           30510.4            -701.4</code></pre>
<p>будет предсказывать значение заработка по значению роста…с учетом значения пола …и с учетом взаимодествия между переменными рост и пол</p>
<div id="--------yxz--yzx----" class="section level5">
<h5>Важно: порядок переменных в формуле имеет первостененное значение y~x+z и y~z+x это две разные модели</h5>
<pre class="r"><code>lm(earn ~ height * sex, data = wages)</code></pre>
<pre><code>## 
## Call:
## lm(formula = earn ~ height * sex, data = wages)
## 
## Coefficients:
##      (Intercept)            height         sexfemale  height:sexfemale  
##         -42677.4            1265.9           30510.4            -701.4</code></pre>
<p>Знак * служит сокращенной записью обозначения того, что мы хотим рассмотреть влияние этих двух переменных на зависимую переменную и хотим учесть их взаимодействие между собой.</p>
<p>Запись ^2 обозначает, что в модели нужно учесть все взаимодействия первого порядка(с одной переменной - +) и все взаимодействия второго порядка (взаимодействия переменных между собой - :)</p>
<pre class="r"><code>lm(earn ~ height + sex + height:sex, data = w1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = earn ~ height + sex + height:sex, data = w1)
## 
## Coefficients:
##    (Intercept)          height         sexmale  height:sexmale  
##       -31845.8           868.3        139602.2         -1683.4</code></pre>
<pre class="r"><code>lm(earn ~ height * sex, data = w1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = earn ~ height * sex, data = w1)
## 
## Coefficients:
##    (Intercept)          height         sexmale  height:sexmale  
##       -31845.8           868.3        139602.2         -1683.4</code></pre>
<pre class="r"><code>lm(earn ~ (height + sex)^2, data = w1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = earn ~ (height + sex)^2, data = w1)
## 
## Coefficients:
##    (Intercept)          height         sexmale  height:sexmale  
##       -31845.8           868.3        139602.2         -1683.4</code></pre>
<p>Если мы захотим рассмотреть модель с тремя независимыми переменными,например добавим в нашу модель рассу, то у нас появяться взаимодействия и третьего порядка - height:sex:race</p>
<p>Тогда мы можем использовать запись ^3, которая будет обозначать, что в модели надо использовать все взаимодействия первого, второго и третьего порядка.</p>
<pre class="r"><code>lm(earn ~ (height + sex + race)^3,data = w1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = earn ~ (height + sex + race)^3, data = w1)
## 
## Coefficients:
##                 (Intercept)                       height  
##                     -166395                         2944  
##                     sexmale                 racehispanic  
##                      491439                       183266  
##                   raceother                    racewhite  
##                      385211                       128984  
##              height:sexmale          height:racehispanic  
##                       -7062                        -2437  
##            height:raceother             height:racewhite  
##                       -6064                        -1993  
##        sexmale:racehispanic            sexmale:raceother  
##                          NA                           NA  
##           sexmale:racewhite  height:sexmale:racehispanic  
##                     -396323                           NA  
##    height:sexmale:raceother     height:sexmale:racewhite  
##                          NA                         6052</code></pre>
<pre class="r"><code>qplot(height, earn, data = w1, alpha = I(1/10), color = sex) + theme_bw() + geom_line(aes(y = predict(lm(earn ~ (height + sex + race)^3,data = w1))))</code></pre>
<p><img src="Part-4-topic-1_files/figure-html/unnamed-chunk-106-1.png" width="672" /></p>
</div>
<div id="-----r" class="section level4">
<h4>Шпаргалка по формулам моделирования в R</h4>
<ul>
<li>‘~’ Отделяет зависимые переменные справа от независимых переменных слева. К примеру, формула зависимости y от x, z, и w будет выглядеть как y ~ x + z + w.</li>
<li>‘+’ Разделяет независимые переменные.</li>
<li>‘:’ Обозначает взаимодействие между независимыми переменными. Описание y как величины зависимой от x, z, и взаимодействия между x и z будет выглядеть как y ~ x + z + x:z.</li>
<li>‘*’ Короткая запись всех возможных взаимодействий между переменными. Код y ~ x* z* w равнозначен y ~ x + z + w + x:z + x:w + z:w + x:z:w.</li>
<li>‘^’ Обозначает взаимодействие определенного уровня. Так код y ~ (x + z + w)^2 равнозначен y ~ x + z + w + x:z + x:w + z:w.</li>
<li>‘.’ Краткая запись обозначающая все остальные переменные в таблице кроме зависимой переменной. Например, если таблица содержит переменные x, y, z, и w, тогда код y ~ . будет равнозначен y ~ x + z + w.</li>
<li>‘-’ Знак миинуса убирает переменную из формулы. Например, y ~ (x + z + w)^2 – x:w равнозначно y ~ x + z + w + x:z + z:w.</li>
<li>‘-1’ Убирает первый коэфициент, заставляя график модельной функции проходить через начало координат .</li>
<li>‘I()’ Элементы внутри скобок интерпретируются численно. Например, y ~ x + (z + w)^2 равнозначно y ~ x + z + w + z:w. Но, код y ~ x + I((z + w)^2) равнозначен y ~ x + h, где h новая переменная, полученная возведением в квадрат суммы z и w.</li>
<li>‘function’ Любая математическая функция может быть использована в формуле. Например, log(y) ~ x + z + w попытается описать зависимость log(y) от x, z, и w.</li>
</ul>
</div>
<div id="---" class="section level4">
<h4>Анализ моделей множественной регресии</h4>
<p>Все задачи, что стояли перед нами по анализу моделей линейной регресси актуальны и здесь. Но для моделей множественной регрессии появляется еще одна задача - определение вклада каждой отдеьной переменной в итоговую модель и заключение о ее необходимости пребывания в оной.</p>
<p>Еще одна проблема, кроме того, что переменные, которые вы добавили могут незначительно влиять на вашу модель, заключается в том, что если присутствующие в модели переменные кореллируют, это может вносить сильную ошибку в их р-значения.</p>
<p>Для того чтобы избежать подобной ситуации, известной под названием мультиколлинеарность, вам придется проверить коэффиценты корреляции для всех ваших переменных:</p>
<pre class="r"><code>cor(wages$height, wages$ed)</code></pre>
<pre><code>## [1] 0.1140473</code></pre>
<pre class="r"><code>cor(wages$height, wages$age)</code></pre>
<pre><code>## [1] -0.1337271</code></pre>
<pre class="r"><code>cor(wages$height, as.numeric(wages$sex))</code></pre>
<pre><code>## [1] -0.7036717</code></pre>
<p>Если некоторые из ваших переменных значимо коррелируют, то вам надо выбрать одну из них, отказавшись от другой.</p>
<p>Помимо этих проблем, для моделей соержащих множество переменных проблемой становится то, что с увеличением количества переменных увеличивает шанс того, для какой-то из переменных мы полим неадекватные р-значение просто в результате неудачной выборки.</p>
<p>Например, р-значение &lt; 0.05 будет каждым двадцатым среди бесконечного множества p-значений, просто по закону больших чисел.</p>
<p>Тогда, вероятность того, что хотя бы одно р-значение &lt; 0.05 = 0.05. Вероятность того, что хотя бы одно из двух р-значений &lt; 0.05 = 0.098. … … … Вероятность того, что хотя бы одно из двадцати р-значений &lt; 0.05 = 0.64</p>
<p>Для того, чтобы не отвергнуть реально влияющие на вашу модель переменные в результате такого эффекта рекомендуется использовать один из следующи подходов</p>
<ol style="list-style-type: decimal">
<li>Использовать более низкое α значение для определения значимости (например равное α / p)</li>
<li>Проверять в первую очередь то, чо вся модель статистически значима и уже исходя из этого принимать решение об исключении той или иной переменной.</li>
</ol>
<p>Например, для модели m4</p>
<pre class="r"><code>summary(m4)</code></pre>
<pre><code>## 
## Call:
## lm(formula = earn ~ height + sex + height:sex, data = wages)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -49699 -20090  -5034  11553 271709 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)      -42677.4    30488.0  -1.400  0.16180   
## height             1265.9      434.9   2.911  0.00366 **
## sexfemale         30510.4    39644.1   0.770  0.44166   
## height:sexfemale   -701.4      585.8  -1.197  0.23141   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 29340 on 1375 degrees of freedom
## Multiple R-squared:  0.1205, Adjusted R-squared:  0.1186 
## F-statistic: 62.82 on 3 and 1375 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Полученные данные означают, что модель m4 имеет значимую разнцу в точности предсказания по сравнению с моделью m1. Т.е. другими словами, т.к. разница между моделями заключалась в наличии в модели m4 переменной пол(sex), то включение переменной пол в нашу модель улучшает ее точность, а значит переменная пол имеет право в ней присутствовать.</p>
<p>Если мы рассмотрим данные, полученные от функции anova() только для одной модели m4, то мы увидим, что</p>
<pre class="r"><code>anova(m4)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: earn
##              Df     Sum Sq    Mean Sq  F value    Pr(&gt;F)    
## height        1 1.1448e+11 1.1448e+11 132.9410 &lt; 2.2e-16 ***
## sex           1 4.6562e+10 4.6562e+10  54.0720 3.307e-13 ***
## height:sex    1 1.2343e+09 1.2343e+09   1.4334    0.2314    
## Residuals  1375 1.1840e+12 8.6112e+08                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>р-значение для переменной height:sex больше предельного р-знаения, а значит, модель содержащая переменные heights + sex + heights:sex не значимо лучше чем модель содержащая переменные heights + sex, а значит от переменной height:sex мы можем отказаться.</p>
</div>
<div id="-----------" class="section level4">
<h4>Итоговый алгоритм исследования модели будет заключаться в получении и интерпретации следующих значений</h4>
<ul>
<li>Коэффициенты - coef(mod)</li>
<li>Остатки - resid(mod)</li>
<li>Доверительный интервал - confint(mod)</li>
<li>P-значения - summary(mod)</li>
<li>Сравнение вариантов модели - anova(mod1, mod2)</li>
</ul>
</div>
</div>

</div> <!-- lessonContent -->
</div> <!-- lessonPage -->


<script type="text/javascript">
  var lesson = window.location.href.match(/lesson-[0-9]+/g);
  if (lesson !== null) {
    lesson = 'nav-' + lesson[0];
    $('#'+lesson).addClass('current');
  }

  $('#show-answer').on("click", function() {
    $('#show-answer').addClass('showing');
    $('#model-answer').addClass('showing');
  })
</script>
  </div> <!-- articleBandContent -->
</div> <!-- pageContent -->

<!-- <div id="rStudioFooter" class="band full">
<div class="bandContent">
  <div id="copyright">Создано с помощью R в Лаборатории Агроэкологического Мониторинга и Прогнозирования экосистем - <a href="http://lamp-lab.ru">ЛАМП</a></div>
  <div id="logos">
<a href="https://twitter.com/rstudio" class="footerLogo twitter"></a>
  <a href="https://github.com/rstudio" class="footerLogo gitHub"></a>
   <a href="https://www.linkedin.com/company/rstudio-inc" class="footerLogo linkedIn"></a>
  <a href="https://www.facebook.com/pages/RStudio-Inc/267733656584415" Class="footerLogo facebook"></a>
  </div>
</div>
</div> -->

<div class="navbar navbar-default navbar-fixed-bottom">
    <div class="container">
      <p class="navbar-text pull-left">© 2019 - Создано с помощью R в Лаборатории Агроэкологического Мониторинга и Прогнозирования экосистем -
      <a href="http://lamp-lab.ru">ЛАМП</a>
      </p>
    </div>
</div>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
